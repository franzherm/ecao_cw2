{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Particle Swarm Optimisation for Knights Covering Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#necessary python library imports\n",
    "import numpy as np\n",
    "from collections.abc import Callable\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Particle Swarm Optimisation class\n",
    "\n",
    "Fitness function is an error function, so we want to minimise it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PSO:\n",
    "    def __init__(self, board_size: int, fitness_function: Callable[[np.ndarray], np.ndarray], \n",
    "                 penalty_function: Callable[[np.ndarray, int], np.ndarray] = (lambda _: 0), num_particles: int = 100, c1: float = 1.0, \n",
    "                 c2: float = 1.0, max_velocity: float = 4.0, min_velocity: float = -4.0, inertia: float = 1.0, rng_seed: int = None) -> None:\n",
    "        \n",
    "        #check for sensible hyperparameter selection\n",
    "        assert min_velocity < max_velocity, \"Max velocity has to be greater than the min velocity.\" \n",
    "        assert num_particles > 1, \"There has to be at least one particle\"\n",
    "        assert c1 >= 0, \"c1 has to be greater than 0\"\n",
    "        assert c2 >= 0, \"c2 has to be greater than 0\"\n",
    "        assert board_size > 3, \"board size has to be at least 3\"\n",
    "        #condition on sensible inertia values as proposed in: \"F. van den Bergh. An Analysis of Particle Swarm Optimizers (2002)\"\n",
    "        assert inertia > c1+c2 / 2 - 1 and inertia >= 0, \"Inertia must be positive and greater than (c1 + c2) / 2 -1\"\n",
    "\n",
    "        #assign hyperparameters to object variables\n",
    "        self.board_size = board_size\n",
    "        self.fitness_function = fitness_function\n",
    "        self.penalty_function = penalty_function\n",
    "        self.num_particles = num_particles\n",
    "        self.c1 = c1\n",
    "        self.c2 = c2\n",
    "        self.max_velocity = max_velocity\n",
    "        self.min_velocity = min_velocity\n",
    "        self.inertia = inertia\n",
    "        self.rng = np.random.default_rng(rng_seed)\n",
    "\n",
    "        #initialise particles and velocities\n",
    "        self.particle_positions = self.rng.integers(low=0, high=1, endpoint=True, size=(self.num_particles, self.board_size**2))\n",
    "        self.particle_best_pos = self.particle_positions.copy()\n",
    "        self.particle_velocities = self.rng.random(size=(self.num_particles, self.board_size**2)) * self.max_velocity\n",
    "        \n",
    "        #initialise global best\n",
    "        self.particle_fitness = self.compute_penalty_fitness(self.particle_positions, 0)\n",
    "        self.particle_best_fitness = self.particle_fitness.copy()\n",
    "\n",
    "        best_fitness = np.min(self.particle_fitness) #find best fitness value\n",
    "        best_indices = np.argwhere(self.particle_fitness == best_fitness) #find all particles that have the best fitness value\n",
    "        best_chosen_index = self.rng.choice(best_indices) #randomly choose one of the particles with the best fitness values\n",
    "\n",
    "        self.global_best_location = self.particle_positions[best_chosen_index].copy()\n",
    "        self.global_best_fitness = self.particle_fitness[best_chosen_index]\n",
    "    \n",
    "    def compute_penalty_fitness(self, particle_positions: np.ndarray, k: int):\n",
    "        ''' Computes the fitness subtracted by the penalty for invalid solutions (i.e. not all squares attacked or occupied).\n",
    "            The penalty function receives a parameter 'k', which indicates the current iteration number.\n",
    "        '''\n",
    "        return self.fitness_function(particle_positions) + self.penalty_function(particle_positions, k)\n",
    "\n",
    "    def optimise(self, num_iterations = 10_000):\n",
    "        ''' Starts the optimisation loop. The num_iterations parameter specifies the terimination criterion as \n",
    "            the number of iterations that will be done.\n",
    "        '''\n",
    "\n",
    "        # initialise random numbers used in velocity computation\n",
    "        r1 = np.empty(shape=self.num_particles)\n",
    "        r2 = np.empty(shape=self.num_particles)\n",
    "        r_sigmoid = np.empty(shape=self.num_particles)\n",
    "\n",
    "        for i in range(num_iterations):\n",
    "            #update random numbers\n",
    "            self.rng.random(size=self.num_particles, out=r1)\n",
    "            self.rng.random(size=self.num_particles, out=r2)\n",
    "            self.rng.random(size=self.num_particles, out=r_sigmoid)\n",
    "\n",
    "            # update velocities\n",
    "            reduced_current_velocity = self.inertia * self.particle_velocities\n",
    "            local_velocity_component = self.c1 * r1 * (self.particle_best_pos - self.particle_positions)\n",
    "            global_velocity_component = self.c2 * r2 * (self.global_best_location - self.particle_positions)\n",
    "\n",
    "            new_velocity = reduced_current_velocity + local_velocity_component + global_velocity_component\n",
    "            self.particle_velocities = np.clip(new_velocity, a_max= self.max_velocity, a_min= self.min_velocity)\n",
    "\n",
    "            # update positions\n",
    "            #the original algorithm was flawed in regards to the position update\n",
    "            #see https://www.researchgate.net/publication/224302958_A_novel_binary_particle_swarm_optimization\n",
    "            sigmoid = 1/(1 + np.exp(-self.particle_velocities))\n",
    "            change_indices = r_sigmoid < sigmoid\n",
    "\n",
    "            #dimensions in which the normalised velocity value is greater than random value change their location value from 0 to 1 or vice versa\n",
    "            self.particle_positions[change_indices] == (self.particle_positions[change_indices] + 1) % 2\n",
    "\n",
    "            # calculate fitness\n",
    "            self.particle_fitness = self.compute_penalty_fitness(self.particle_positions, i)\n",
    "\n",
    "            # update best positions\n",
    "            # local best positions\n",
    "            new_best_local_fitness_indices = self.particle_fitness > self.particle_best_fitness\n",
    "            self.particle_best_fitness[new_best_local_fitness_indices] = self.particle_fitness[new_best_local_fitness_indices]\n",
    "            self.particle_best_pos[new_best_local_fitness_indices] = self.particle_positions[new_best_local_fitness_indices]\n",
    "\n",
    "            # global best positions\n",
    "            new_best_global_fitness = np.min(self.particle_fitness) #find best fitness value\n",
    "            new_best_global_fitness_indices = np.argwhere(self.particle_fitness == new_best_global_fitness) #find all particles that have the best fitness value\n",
    "            new_best_chosen_global_fitness_index = self.rng.choice(new_best_global_fitness_indices) #randomly choose one of the particles with the best fitness values\n",
    "\n",
    "            #update best solution \n",
    "            if new_best_global_fitness < self.global_best_fitness:\n",
    "                self.global_best_fitness = new_best_global_fitness\n",
    "                self.global_best_location = self.particle_positions[new_best_chosen_global_fitness_index].copy()\n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitness and penalty functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1]\n",
      " [0 2]\n",
      " [0 3]\n",
      " [1 0]\n",
      " [1 2]\n",
      " [1 3]\n",
      " [1 4]\n",
      " [2 0]\n",
      " [2 1]\n",
      " [2 2]\n",
      " [2 3]\n",
      " [2 4]\n",
      " [3 0]\n",
      " [3 1]\n",
      " [3 2]\n",
      " [3 4]\n",
      " [4 0]\n",
      " [4 1]\n",
      " [4 3]]\n"
     ]
    }
   ],
   "source": [
    "def compute_covered_squares(particle_position: np.ndarray, binary_space: bool = True, board_size: int = None) -> np.ndarray:\n",
    "    ''' \n",
    "    Computes all covered squares given the position of a single particle. \n",
    "    Covered squares are defined as positions on the chessboard that are either occupied or attacked by a knight.\n",
    "    '''\n",
    "    if binary_space:\n",
    "        board_size = int(np.sqrt(particle_position.shape[0]))\n",
    "        particle_position = particle_position.reshape((board_size, board_size))\n",
    "    else:\n",
    "        assert board_size is not None, \"When using integer space, you have to specify the board_size parameter\"\n",
    "        particle_position = convert_integer_to_binary_space(particle_position, board_size)\n",
    "\n",
    "    knight_position_indices = np.argwhere(particle_position)\n",
    "\n",
    "    covered_positions = []\n",
    "    relative_jump_positions = [\n",
    "        #(x_change, y_change)\n",
    "        ( 0, 0),#current position\n",
    "        (-1,-2),#left top\n",
    "        (+1,-2),#left bottom\n",
    "        (-1,+2),#right top\n",
    "        (+1,+2),#right bottom\n",
    "        (-2,-1),#top left\n",
    "        (-2,+1),#top right\n",
    "        (+2,-1),#bottom left\n",
    "        (+2,+1),#bottom right\n",
    "    ]\n",
    "\n",
    "    for relative_jump_position in relative_jump_positions:\n",
    "        #calculate positions that the knights can jump to\n",
    "        positions = knight_position_indices.copy()\n",
    "        positions += relative_jump_position   \n",
    "\n",
    "        #calculated positions are only valid if they are within the bounds of the chessboard     \n",
    "        valid_indices = np.all((positions >= 0) & (positions < board_size), axis=1)\n",
    "\n",
    "        #append valid positions to the list of attacked positions\n",
    "        covered_positions.extend(positions[valid_indices])\n",
    "    \n",
    "    covered_positions = np.array(covered_positions)\n",
    "    unique_positions = np.unique(covered_positions, axis=0)\n",
    "\n",
    "    return unique_positions\n",
    "\n",
    "def convert_integer_to_binary_space(particle_position: np.ndarray, board_size: int):\n",
    "    binary_position = np.zeros(shape=(board_size, board_size)) #initialise board\n",
    "    knight_position_indices = np.cumsum(particle_position) #calculate knight positions on board\n",
    "    knight_position_indices = knight_position_indices - 1 #set the reference point for the first knight to -1 so that 0 always indicates an unused knight\n",
    "    \n",
    "    #keep only valid positions\n",
    "    valid_position_indices = knight_position_indices >= 0 & knight_position_indices < board_size**2 \n",
    "    knight_position_indices = knight_position_indices[valid_position_indices]\n",
    "\n",
    "    binary_position[knight_position_indices] = 1 #set knights on board\n",
    "    return binary_position\n",
    "\n",
    "\n",
    "def compute_num_of_covered_squares(particle_position: np.ndarray, binary_space: bool = True, board_size: int = None) -> int:\n",
    "    return compute_covered_squares(particle_position, binary_space, board_size).shape[0]\n",
    "\n",
    "\n",
    "a = np.array([0,1,1,0,0, \n",
    "              0,0,0,0,0, \n",
    "              0,0,1,0,1, \n",
    "              0,1,0,0,0,\n",
    "              1,0,0,0,0,])\n",
    "covered_squares = compute_covered_squares(a)\n",
    "print(covered_squares)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fitness function implementations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitness_binary_space_pso_paper(particle_positions: np.ndarray) -> np.ndarray:\n",
    "    '''From paper Investigating binary PSO parameter influence on the knights cover problem by N. Franken and A.P. Engelbrecht (2005)'''\n",
    "    num_covered_squares = np.apply_along_axis(compute_num_of_covered_squares, axis=1, arr = particle_positions)\n",
    "    num_knights = np.sum(particle_positions, axis=1)\n",
    "    total_num_squares = particle_positions.shape[1]\n",
    "    num_empty_squares = total_num_squares - num_covered_squares\n",
    "\n",
    "    fitness = num_empty_squares + num_knights + total_num_squares/num_covered_squares\n",
    "    return fitness\n",
    "\n",
    "def fitness_integer_space_pso_paper(particle_positions: np.ndarray, board_size:int = None) -> np.ndarray:\n",
    "    num_covered_squares = np.apply_along_axis(compute_num_of_covered_squares, axis=1, arr=particle_positions, binary_space=True, board_size=board_size)\n",
    "    num_knights = np.sum((particle_positions > 0), axis=1)\n",
    "    total_num_squares = board_size**2\n",
    "    num_empty_squares = total_num_squares - num_covered_squares\n",
    "\n",
    "    fitness = num_empty_squares + num_knights + total_num_squares/num_covered_squares\n",
    "    return fitness\n",
    "\n",
    "def fitness_binary_space_simple(particle_positions: np.ndarray) -> np.ndarray:\n",
    "    num_knights = np.sum(particle_positions, axis=1)\n",
    "    return num_knights\n",
    "\n",
    "def fitness_integer_space_simple(particle_positions: np.ndarray, board_size:int = None) -> np.ndarray:\n",
    "    num_knights = np.sum((particle_positions > 0), axis=1)\n",
    "    return num_knights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Penalty function implementations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#computes penalty for conventional search space depending on the ratio of empty squares\n",
    "def penalty_binary_space(particle_positions: np.ndarray, iteration_number: int):\n",
    "    ratio_of_empty_squares = (particle_positions.shape[1] - compute_num_of_covered_squares(particle_positions)) / particle_positions.shape[1]\n",
    "\n",
    "    penalties = iteration_number * ratio_of_empty_squares #use ratio so that the penalty is independent of the board size\n",
    "    return penalties\n",
    "\n",
    "#computes penalty for integer search space depending on ratio of empty squares and whether the knights are positioned outside the board\n",
    "def penalty_integer_space(particle_positions:np.ndarray, iteration_number: int, board_size):\n",
    "    ratio_of_empty_squares = (board_size**2 - compute_num_of_covered_squares(particle_positions)) / board_size**2\n",
    "    last_knight_location = np.sum(particle_positions, axis=1)\n",
    "    distance_from_last_square = last_knight_location - board_size**2\n",
    "\n",
    "    penalties = iteration_number * (ratio_of_empty_squares + np.maximum(0, distance_from_last_square))\n",
    "    return penalties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Search Algorithm class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomSearch:\n",
    "    def __init__(self, board_size: int, fitness_function: Callable[[np.ndarray], np.ndarray], \n",
    "                 penalty_function: Callable[[np.ndarray, int], np.ndarray] = (lambda _: 0), rng_seed: int = None):\n",
    "        \n",
    "        self.board_size = board_size\n",
    "        self.fitness_function = fitness_function\n",
    "        self.penalty_function = penalty_function\n",
    "        self.rng = np.random.default_rng(rng_seed)\n",
    "\n",
    "        self.current_solution = self.rng.integers(low=0, high=1, endpoint=True, size=board_size**2)\n",
    "        self.best_solution = self.current_solution.copy()\n",
    "        self.best_fitness = self.compute_penalty_fitness(self.best_solution, 0)\n",
    "        \n",
    "    def compute_penalty_fitness(self, particle_positions: np.ndarray, k: int):\n",
    "        ''' Computes the fitness subtracted by the penalty for invalid solutions (i.e. not all squares attacked or occupied).\n",
    "            The penalty function receives a parameter 'k', which indicates the current iteration number.\n",
    "        '''\n",
    "        return self.fitness_function(particle_positions) + self.penalty_function(particle_positions, k)\n",
    "        \n",
    "    def optimise(self, num_iterations= 10_000):\n",
    "        for i in range(num_iterations):\n",
    "            #select random position to be altered\n",
    "            mutation_index = self.rng.integers(low=0, high=self.current_solution.shape[0])\n",
    "            #set element at index position to it's binary complement\n",
    "            self.current_solution[mutation_index] = (self.current_solution[mutation_index]+1) % 2 \n",
    "            #compute fitness of altered solution\n",
    "            fitness = self.compute_penalty_fitness(self.current_solution, i)\n",
    "            \n",
    "            #update best solution\n",
    "            if(fitness < self.best_fitness):\n",
    "                self.best_solution = self.current_solution.copy()\n",
    "                self.best_fitness = fitness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stochastic Hillclimb Algorithm class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#implements First choice stochastic hill climb as per Artificial Intelligence: A Modern Approach, Global Edition, Fourth Edition\n",
    "class StochasticHillclimb:\n",
    "    def __init__(self, board_size: int, fitness_function: Callable[[np.ndarray], np.ndarray], \n",
    "                 penalty_function: Callable[[np.ndarray, int], np.ndarray] = (lambda _: 0), allowed_plateau_steps: int = 100, rng_seed: int = None):\n",
    "        \n",
    "        self.board_size = board_size\n",
    "        self.fitness_function = fitness_function\n",
    "        self.penalty_function = penalty_function\n",
    "        self.rng = np.random.default_rng(rng_seed)\n",
    "        self.allowed_plateau_steps = allowed_plateau_steps\n",
    "\n",
    "        self.current_solution = self.rng.integers(low=0, high=1, endpoint=True, size=board_size**2)\n",
    "        self.current_fitness = self.compute_penalty_fitness(self.current_solution, 0)\n",
    "\n",
    "    def compute_penalty_fitness(self, particle_positions: np.ndarray, k: int):\n",
    "        ''' Computes the fitness subtracted by the penalty for invalid solutions (i.e. not all squares attacked or occupied).\n",
    "            The penalty function receives a parameter 'k', which indicates the current iteration number.\n",
    "        '''\n",
    "        return self.fitness_function(particle_positions) + self.penalty_function(particle_positions, k)\n",
    "\n",
    "    def optimise(self, num_iterations= 10_000):\n",
    "        num_plateau_steps = 0\n",
    "\n",
    "        for i in range(num_iterations):\n",
    "            neighbour_permutation = self.rng.permutation(self.current_solution.shape[0])\n",
    "\n",
    "            for neighbour_index in neighbour_permutation:\n",
    "                neighbour_solution = self.current_solution.copy()\n",
    "                neighbour_solution[neighbour_index] = (neighbour_solution[neighbour_index]+1) % 2 \n",
    "                neighbour_fitness = self.compute_penalty_fitness(neighbour_fitness, i)\n",
    "\n",
    "                #choose first neighbour with more optimal fitness (in this case, lower fitness value as we want to minimise the function)\n",
    "                if neighbour_fitness <= self.current_fitness:\n",
    "                    #check if fintess is on a plateau\n",
    "                    if neighbour_fitness == self.current_fitness:\n",
    "                        num_plateau_steps += 1 #increment plateau step counter\n",
    "\n",
    "                        #cancel optimisation if maximum number of plateau steps is reached\n",
    "                        if num_plateau_steps > self.allowed_plateau_steps: return\n",
    "                        \n",
    "                    else: #reset plateau step counter if fitness is reduced\n",
    "                        num_plateau_steps = 0\n",
    "\n",
    "                    self.current_solution = neighbour_solution\n",
    "                    self.current_fitness = neighbour_fitness\n",
    "                    break #dont consider the remaining neighbours\n",
    "            \n",
    "                return # no improved solution was found among the neighbours -> peak has been reached"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def increment_indices(current_indices, max_indices):\n",
    "    current_indices[-1] += 1\n",
    "    for i in reversed(range(len(current_indices))):\n",
    "        if current_indices[i] > max_indices[i]:\n",
    "            current_indices[i] = 0\n",
    "            if i != 0:\n",
    "                current_indices[i-1] +=1\n",
    "        else:\n",
    "            break\n",
    "    return current_indices\n",
    "\n",
    "def fetch_algorithm_parameters(algorithm_config, parameter_indices):\n",
    "    config_value_list = list(algorithm_config.values())\n",
    "    parameters = [config_value_list[parameter][parameter_index] for parameter, parameter_index in enumerate(parameter_indices)]\n",
    "\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimentation config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run configuration for particle swarm optimisation\n",
    "pso_config = {\n",
    "    \"num_particles\": [100],\n",
    "    \"fitness_and_penalty_functions\": [(),()],\n",
    "    \"c1_c2_and_inertia\": [(),()],\n",
    "    \"max_min_velocity\": [(),()],\n",
    "}\n",
    "\n",
    "#run configuration for random search\n",
    "rs_config = {\n",
    "    \"fitness_and_penalty_functions\": [(),()]\n",
    "}\n",
    "\n",
    "#run configuration for stochastic hillclimb\n",
    "shc_config = {\n",
    "    \"fitness_and_penalty_functions\": [(),()],\n",
    "    \"allowed_plateau_steps\": []\n",
    "}\n",
    "\n",
    "#meta run config for all experiments\n",
    "run_config = {\n",
    "    \"optimisation_algorithm\": [PSO, RandomSearch, StochasticHillclimb],\n",
    "    \"algorithm_configs\":[pso_config, rs_config, shc_config],\n",
    "    \"board_sizes\": list(np.arange(start=4, stop=25)),\n",
    "    \"runs_per_experiment\": 10,\n",
    "    \"iterations_per_run\": 10000,\n",
    "    \"rng_seed\": []\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PSO experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m rng \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mdefault_rng(run_config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrng_seed\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m      2\u001b[0m iterations_per_run \u001b[38;5;241m=\u001b[39m run_config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miterations_per_run\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# run each optimisation algorithm\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "#TODO: make sure that the order of parameters in config corresponds to order of parameters in algorithm constructor\n",
    "rng = np.random.default_rng(run_config[\"rng_seed\"])\n",
    "iterations_per_run = run_config[\"iterations_per_run\"]\n",
    "\n",
    "# run each optimisation algorithm\n",
    "for optimiser_id, algorithm in tqdm(enumerate(run_config[\"optimisation_algorithm\"]), desc=\"Optimisation Algorithms\", position=0, leave=False):\n",
    "    algorithm_config = pso_config[\"algorithm_configs\"][optimiser_id] #fetch experiment config for the current optimisation algorithm\n",
    "    max_parameter_indices = np.array([len(x)-1 for x in algorithm_config.values()], dtype=int) #compute the maximum indices for each config parameter\n",
    "    num_of_experiments = np.cumprod(max_parameter_indices + 1)[-1] #compute the number of experiments to run based on number of values in config\n",
    "    current_parameter_indices = np.zeros(len(algorithm_config), dtype= int) #initialise current parameter indices to 0\n",
    "\n",
    "    #run all experiments\n",
    "    for experiment_index in tqdm(range(num_of_experiments), desc=\"Experiments\", position=1, leave=False):\n",
    "        parameters = fetch_algorithm_parameters(algorithm_config, current_parameter_indices)\n",
    "        parameters.append(rng) #append random number generator to parameters\n",
    "        parameters = tuple(parameters)\n",
    "\n",
    "        #run all runs of the same experiment\n",
    "        for run in tqdm(range(run_config[\"runs_per_experiment\"]), desc=\"Runs\", position=2, leave=False):\n",
    "            optimiser = algorithm(parameters) #initialise optimisation algorithm with parameters\n",
    "            optimiser.optimise(iterations_per_run) #perform optimisation\n",
    "        \n",
    "        #increment indices of the current algorithm's parameters\n",
    "        current_parameter_indices = increment_indices(current_parameter_indices, max_parameter_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load results file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
