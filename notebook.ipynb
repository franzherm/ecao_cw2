{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Particle Swarm Optimisation for Knights Covering Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#necessary python library imports\n",
    "import numpy as np\n",
    "from collections.abc import Callable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Particle Swarm Optimisation class\n",
    "\n",
    "Fitness function is an error function, so we want to minimise it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PSO:\n",
    "    def __init__(self, board_size: int, fitness_function: Callable[[np.ndarray], np.ndarray], \n",
    "                 penalty_function: Callable[[np.ndarray, int], np.ndarray] = (lambda _: 0), num_particles: int = 100, c1: float = 1.0, \n",
    "                 c2: float = 1.0, max_velocity: float = 4.0, min_velocity: float = -4.0, inertia: float = 1.0, rng_seed: int = None) -> None:\n",
    "        \n",
    "        #check for sensible hyperparameter selection\n",
    "        assert min_velocity < max_velocity, \"Max velocity has to be greater than the min velocity.\" \n",
    "        assert num_particles > 1, \"There has to be at least one particle\"\n",
    "        assert c1 >= 0, \"c1 has to be greater than 0\"\n",
    "        assert c2 >= 0, \"c2 has to be greater than 0\"\n",
    "        assert board_size > 3, \"board size has to be at least 3\"\n",
    "        #condition on sensible inertia values as proposed in: \"F. van den Bergh. An Analysis of Particle Swarm Optimizers (2002)\"\n",
    "        assert inertia > c1+c2 / 2 - 1 and inertia >= 0, \"Inertia must be positive and greater than (c1 + c2) / 2 -1\"\n",
    "\n",
    "        #assign hyperparameters to object variables\n",
    "        self.board_size = board_size\n",
    "        self.fitness_function = fitness_function\n",
    "        self.penalty_function = penalty_function\n",
    "        self.num_particles = num_particles\n",
    "        self.c1 = c1\n",
    "        self.c2 = c2\n",
    "        self.max_velocity = max_velocity\n",
    "        self.min_velocity = min_velocity\n",
    "        self.inertia = inertia\n",
    "        self.rng = np.random.default_rng(rng_seed)\n",
    "\n",
    "        #initialise particles and velocities\n",
    "        self.particle_positions = self.rng.integers(low=0, high=1, endpoint=True, size=(self.num_particles, self.board_size**2))\n",
    "        self.particle_best_pos = self.particle_positions.copy()\n",
    "        self.particle_velocities = self.rng.random(size=(self.num_particles, self.board_size**2)) * self.max_velocity\n",
    "        \n",
    "        #initialise global best\n",
    "        self.particle_fitness = self.compute_penalty_fitness(self.particle_positions, 0)\n",
    "        self.particle_best_fitness = self.particle_fitness.copy()\n",
    "\n",
    "        best_index = np.argmin(self.particle_fitness)\n",
    "        self.global_best_location = self.particle_positions[best_index].copy()\n",
    "        self.global_best_fitness = self.particle_fitness[best_index]\n",
    "    \n",
    "    def compute_penalty_fitness(self, particle_positions: np.ndarray, k: int):\n",
    "        ''' Computes the fitness subtracted by the penalty for invalid solutions (i.e. not all squares attacked or occupied).\n",
    "            The penalty function receives a parameter 'k', which indicates the current iteration number.\n",
    "        '''\n",
    "        return self.fitness_function(particle_positions) + self.penalty_function(particle_positions, k)\n",
    "\n",
    "    def optimise(self, num_iterations = 10_000):\n",
    "        ''' Starts the optimisation loop. The num_iterations parameter specifies the terimination criterion as \n",
    "            the number of iterations that will be done.\n",
    "        '''\n",
    "\n",
    "        # initialise random numbers used in velocity computation\n",
    "        r1 = np.empty(shape=self.num_particles)\n",
    "        r2 = np.empty(shape=self.num_particles)\n",
    "        r_sigmoid = np.empty(shape=self.num_particles)\n",
    "\n",
    "        for i in range(num_iterations):\n",
    "            #update random numbers\n",
    "            self.rng.random(size=self.num_particles, out=r1)\n",
    "            self.rng.random(size=self.num_particles, out=r2)\n",
    "            self.rng.random(size=self.num_particles, out=r_sigmoid)\n",
    "\n",
    "            # update velocities\n",
    "            reduced_current_velocity = self.inertia * self.particle_velocities\n",
    "            local_velocity_component = self.c1 * r1 * (self.particle_best_pos - self.particle_positions)\n",
    "            global_velocity_component = self.c2 * r2 * (self.global_best_location - self.particle_positions)\n",
    "\n",
    "            new_velocity = reduced_current_velocity + local_velocity_component + global_velocity_component\n",
    "            self.particle_velocities = np.clip(new_velocity, a_max= self.max_velocity, a_min= self.min_velocity)\n",
    "\n",
    "            # update positions\n",
    "            #the original algorithm was flawed in regards to the position update\n",
    "            #see https://www.researchgate.net/publication/224302958_A_novel_binary_particle_swarm_optimization\n",
    "            sigmoid = 1/(1 + np.exp(-self.particle_velocities))\n",
    "            change_indices = r_sigmoid < sigmoid\n",
    "\n",
    "            #dimensions in which the normalised velocity value is greater than random value change their location value from 0 to 1 or vice versa\n",
    "            self.particle_positions[change_indices] == (self.particle_positions[change_indices] + 1) % 2\n",
    "\n",
    "            # calculate fitness\n",
    "            self.particle_fitness = self.compute_penalty_fitness(self.particle_positions, i)\n",
    "\n",
    "            # update best positions\n",
    "            # local best positions\n",
    "            new_best_local_fitness_indices = self.particle_fitness > self.particle_best_fitness\n",
    "            self.particle_best_fitness[new_best_local_fitness_indices] = self.particle_fitness[new_best_local_fitness_indices]\n",
    "            self.particle_best_pos[new_best_local_fitness_indices] = self.particle_positions[new_best_local_fitness_indices]\n",
    "\n",
    "            # global best positions\n",
    "            new_best_global_fitness_index = np.argmin(self.particle_fitness)\n",
    "            new_best_global_fitness = self.particle_fitness[new_best_global_fitness_index]\n",
    "\n",
    "            #update best solution \n",
    "            if new_best_global_fitness < self.global_best_fitness:\n",
    "                self.global_best_fitness = new_best_global_fitness\n",
    "                self.global_best_location = self.particle_positions[new_best_global_fitness].copy()\n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitness and penalty functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_covered_squares(particle_position: np.ndarray) -> np.ndarray:\n",
    "    ''' \n",
    "    Computes all covered squares given the position of a single particle. \n",
    "    Covered squares are defined as positions on the chessboard that are either occupied or attacked by a knight.\n",
    "    '''\n",
    "    board_size = int(np.sqrt(particle_position.shape[0]))\n",
    "    knight_position_indices = np.argwhere(particle_position.reshape((board_size, board_size)))\n",
    "\n",
    "    covered_positions = []\n",
    "    relative_jump_positions = [\n",
    "        #(x_change, y_change)\n",
    "        ( 0, 0),#current position\n",
    "        (-1,-2),#left top\n",
    "        (+1,-2),#left bottom\n",
    "        (-1,+2),#right top\n",
    "        (+1,+2),#right bottom\n",
    "        (-2,-1),#top left\n",
    "        (-2,+1),#top right\n",
    "        (+2,-1),#bottom left\n",
    "        (+2,+1),#bottom right\n",
    "    ]\n",
    "\n",
    "    for relative_jump_position in relative_jump_positions:\n",
    "        #calculate positions that the knights can jump to\n",
    "        positions = knight_position_indices.copy()\n",
    "        positions += relative_jump_position   \n",
    "\n",
    "        #calculated positions are only valid if they are within the bounds of the chessboard     \n",
    "        valid_indices = np.all((positions >= 0) & (positions < board_size), axis=1)\n",
    "\n",
    "        #append valid positions to the list of attacked positions\n",
    "        covered_positions.extend(positions[valid_indices])\n",
    "    \n",
    "    covered_positions = np.array(covered_positions)\n",
    "    unique_positions = np.unique(covered_positions, axis=0)\n",
    "\n",
    "    return unique_positions\n",
    "\n",
    "def compute_num_of_covered_squares(particle_position: np.ndarray) -> int:\n",
    "    return compute_covered_squares(particle_position).shape[0]\n",
    "\n",
    "\n",
    "a = np.array([0,1,1,0,0, \n",
    "              0,0,0,0,0, \n",
    "              0,0,1,0,1, \n",
    "              0,1,0,0,0,\n",
    "              1,0,0,0,0,])\n",
    "covered_squares = compute_covered_squares(a)\n",
    "print(covered_squares)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fitness function implementations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitness_binary_space_pso_paper(particle_positions: np.ndarray) -> np.ndarray:\n",
    "    '''From paper Investigating binary PSO parameter influence on the knights cover problem by N. Franken and A.P. Engelbrecht (2005)'''\n",
    "    num_covered_squares = np.apply_along_axis(compute_num_of_covered_squares, axis=1, arr = particle_positions)\n",
    "    num_knights = np.sum(particle_positions, axis=1)\n",
    "    total_num_squares = particle_positions.shape[1]\n",
    "    num_empty_squares = total_num_squares - num_covered_squares\n",
    "\n",
    "    fitness = num_empty_squares + num_knights + total_num_squares/num_covered_squares\n",
    "    return fitness\n",
    "\n",
    "def fitness_integer_space_pso_paper(particle_positions: np.ndarray) -> np.ndarray:\n",
    "    pass\n",
    "\n",
    "def fitness_binary_space_simple(particle_positions: np.ndarray) -> np.ndarray:\n",
    "    pass\n",
    "\n",
    "def fitness_integer_space_simple(particle_positions: np.ndarray) -> np.ndarray:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Penalty function implementations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#computes penalty for conventional search space depending on the ratio of empty squares\n",
    "def penalty_binary_space(particle_positions: np.ndarray, iteration_number: int):\n",
    "    ratio_of_empty_squares = (particle_positions.shape[1] - compute_num_of_covered_squares(particle_positions)) / particle_positions.shape[1]\n",
    "\n",
    "    penalties = iteration_number * ratio_of_empty_squares #use ratio so that the penalty is independent of the board size\n",
    "    return penalties\n",
    "\n",
    "#computes penalty for integer search space depending on ratio of empty squares and whether the knights are positioned outside the board\n",
    "def penalty_integer_space(particle_positions:np.ndarray, iteration_number: int, board_size):\n",
    "    ratio_of_empty_squares = (board_size**2 - compute_num_of_covered_squares(particle_positions)) / board_size**2\n",
    "    last_knight_location = np.sum(particle_positions, axis=1)\n",
    "    distance_from_last_square = last_knight_location - board_size**2\n",
    "\n",
    "    penalties = iteration_number * (ratio_of_empty_squares + np.maximum(0, distance_from_last_square))\n",
    "    return penalties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Search Algorithm class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomSearch:\n",
    "    def __init__(self, board_size: int, fitness_function: Callable[[np.ndarray], np.ndarray], \n",
    "                 penalty_function: Callable[[np.ndarray, int], np.ndarray] = (lambda _: 0), rng_seed: int = None):\n",
    "        \n",
    "        self.board_size = board_size\n",
    "        self.fitness_function = fitness_function\n",
    "        self.penalty_function = penalty_function\n",
    "        self.rng = np.random.default_rng(rng_seed)\n",
    "\n",
    "        self.current_solution = self.rng.integers(low=0, high=1, endpoint=True, size=board_size**2)\n",
    "        self.best_solution = self.current_solution.copy()\n",
    "        self.best_fitness = self.compute_penalty_fitness(self.best_solution, 0)\n",
    "        \n",
    "    def compute_penalty_fitness(self, particle_positions: np.ndarray, k: int):\n",
    "        ''' Computes the fitness subtracted by the penalty for invalid solutions (i.e. not all squares attacked or occupied).\n",
    "            The penalty function receives a parameter 'k', which indicates the current iteration number.\n",
    "        '''\n",
    "        return self.fitness_function(particle_positions) + self.penalty_function(particle_positions, k)\n",
    "        \n",
    "    def optimise(self, num_iterations= 10_000):\n",
    "        for i in range(num_iterations):\n",
    "            #select random position to be altered\n",
    "            mutation_index = self.rng.integers(low=0, high=self.current_solution.shape[0])\n",
    "            #set element at index position to it's binary complement\n",
    "            self.current_solution[mutation_index] = (self.current_solution[mutation_index]+1) % 2 \n",
    "            #compute fitness of altered solution\n",
    "            fitness = self.compute_penalty_fitness(self.current_solution, i)\n",
    "            \n",
    "            #update best solution\n",
    "            if(fitness < self.best_fitness):\n",
    "                self.best_solution = self.current_solution.copy()\n",
    "                self.best_fitness = fitness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stochastic Hillclimb Algorithm class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#implements First choice stochastic hill climb as per Artificial Intelligence: A Modern Approach, Global Edition, Fourth Edition\n",
    "class StochasticHillclimb:\n",
    "    def __init__(self, board_size: int, fitness_function: Callable[[np.ndarray], np.ndarray], \n",
    "                 penalty_function: Callable[[np.ndarray, int], np.ndarray] = (lambda _: 0), allowed_plateau_steps: int = 100, rng_seed: int = None):\n",
    "        \n",
    "        self.board_size = board_size\n",
    "        self.fitness_function = fitness_function\n",
    "        self.penalty_function = penalty_function\n",
    "        self.rng = np.random.default_rng(rng_seed)\n",
    "        self.allowed_plateau_steps = allowed_plateau_steps\n",
    "\n",
    "        self.current_solution = self.rng.integers(low=0, high=1, endpoint=True, size=board_size**2)\n",
    "        self.current_fitness = self.compute_penalty_fitness(self.current_solution, 0)\n",
    "\n",
    "    def compute_penalty_fitness(self, particle_positions: np.ndarray, k: int):\n",
    "        ''' Computes the fitness subtracted by the penalty for invalid solutions (i.e. not all squares attacked or occupied).\n",
    "            The penalty function receives a parameter 'k', which indicates the current iteration number.\n",
    "        '''\n",
    "        return self.fitness_function(particle_positions) + self.penalty_function(particle_positions, k)\n",
    "\n",
    "    def optimise(self, num_iterations= 10_000):\n",
    "        num_plateau_steps = 0\n",
    "\n",
    "        for i in range(num_iterations):\n",
    "            neighbour_permutation = self.rng.permutation(self.current_solution.shape[0])\n",
    "\n",
    "            for neighbour_index in neighbour_permutation:\n",
    "                neighbour_solution = self.current_solution.copy()\n",
    "                neighbour_solution[neighbour_index] = (neighbour_solution[neighbour_index]+1) % 2 \n",
    "                neighbour_fitness = self.compute_penalty_fitness(neighbour_fitness, i)\n",
    "\n",
    "                #choose first neighbour with more optimal fitness (in this case, lower fitness value as we want to minimise the function)\n",
    "                if neighbour_fitness <= self.current_fitness:\n",
    "                    #check if fintess is on a plateau\n",
    "                    if neighbour_fitness == self.current_fitness:\n",
    "                        num_plateau_steps += 1 #increment plateau step counter\n",
    "\n",
    "                        #cancel optimisation if maximum number of plateau steps is reached\n",
    "                        if num_plateau_steps > self.allowed_plateau_steps: return\n",
    "                        \n",
    "                    else: #reset plateau step counter if fitness is reduced\n",
    "                        num_plateau_steps = 0\n",
    "\n",
    "                    self.current_solution = neighbour_solution\n",
    "                    self.current_fitness = neighbour_fitness\n",
    "                    break #dont consider the remaining neighbours\n",
    "            \n",
    "                return # no improved solution was found among the neighbours -> peak has been reached"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimentation config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load results file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
