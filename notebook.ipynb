{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Particle Swarm Optimisation for Knights Covering Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#necessary python library imports\n",
    "import numpy as np\n",
    "from collections.abc import Callable\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Particle Swarm Optimisation class\n",
    "\n",
    "Fitness function is an error function, so we want to minimise it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def none_value_wrapper(value, default):\n",
    "    if value is None:\n",
    "        value = default\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PSO:\n",
    "    def __init__(self, board_size: int, fitness_function: Callable[[np.ndarray], np.ndarray], \n",
    "                 penalty_function: Callable[[np.ndarray, int], np.ndarray] = (lambda x,y: 0), num_particles: int = 100, c1: float = 1.0, \n",
    "                 c2: float = 1.0, inertia: float = 1.0, max_velocity: float = 4.0, min_velocity: float = -4.0, \n",
    "                 rng: np.random.Generator = np.random.default_rng(None)) -> None:\n",
    "        \n",
    "        #check for sensible hyperparameter selection\n",
    "        assert min_velocity < max_velocity, \"Max velocity has to be greater than the min velocity.\" \n",
    "        assert num_particles > 1, \"There has to be at least one particle\"\n",
    "        assert c1 >= 0, \"c1 has to be greater than 0\"\n",
    "        assert c2 >= 0, \"c2 has to be greater than 0\"\n",
    "        assert board_size > 3, \"board size has to be at least 3\"\n",
    "        #condition on sensible inertia values as proposed in: \"F. van den Bergh. An Analysis of Particle Swarm Optimizers (2002)\"\n",
    "        assert inertia > c1+c2 / 2 - 1 and inertia >= 0, \"Inertia must be positive and greater than (c1 + c2) / 2 -1\"\n",
    "\n",
    "        #assign hyperparameters to object variables\n",
    "        self.board_size = board_size\n",
    "        self.fitness_function = fitness_function\n",
    "        self.penalty_function = none_value_wrapper(penalty_function, default=(lambda x,y: 0))\n",
    "        self.num_particles = none_value_wrapper(num_particles, default=100)\n",
    "        self.c1 = none_value_wrapper(c1, default=1.0)\n",
    "        self.c2 = none_value_wrapper(c2, default=1.0)\n",
    "        self.max_velocity = none_value_wrapper(max_velocity,4.0)\n",
    "        self.min_velocity = none_value_wrapper(min_velocity,-4.0)\n",
    "        self.inertia = none_value_wrapper(inertia, default=1.0)\n",
    "        self.rng = none_value_wrapper(rng, np.random.default_rng(None))\n",
    "\n",
    "        #initialise particles and velocities\n",
    "        self.particle_positions = self.rng.integers(low=0, high=1, endpoint=True, size=(self.num_particles, self.board_size**2))\n",
    "        self.particle_best_pos = self.particle_positions.copy()\n",
    "        self.particle_velocities = self.rng.random(size=(self.num_particles, self.board_size**2)) * self.max_velocity\n",
    "        \n",
    "        #initialise global best\n",
    "        self.particle_fitness = self.compute_penalty_fitness(self.particle_positions, 0)\n",
    "        self.particle_best_fitness = self.particle_fitness.copy()\n",
    "\n",
    "        best_fitness = np.min(self.particle_fitness) #find best fitness value\n",
    "        best_indices = np.argwhere(self.particle_fitness == best_fitness) #find all particles that have the best fitness value\n",
    "        best_chosen_index = self.rng.choice(best_indices) #randomly choose one of the particles with the best fitness values\n",
    "\n",
    "        self.global_best_location = self.particle_positions[best_chosen_index].copy()\n",
    "        self.global_best_fitness = self.particle_fitness[best_chosen_index]\n",
    "    \n",
    "    def compute_penalty_fitness(self, particle_positions: np.ndarray, k: int):\n",
    "        ''' Computes the fitness subtracted by the penalty for invalid solutions (i.e. not all squares attacked or occupied).\n",
    "            The penalty function receives a parameter 'k', which indicates the current iteration number.\n",
    "        '''\n",
    "        return self.fitness_function(particle_positions) + self.penalty_function(particle_positions, k)\n",
    "\n",
    "    def optimise(self, iterator):\n",
    "        ''' Starts the optimisation loop. The num_iterations parameter specifies the terimination criterion as \n",
    "            the number of iterations that will be done.\n",
    "        '''\n",
    "\n",
    "        # initialise random numbers used in velocity computation\n",
    "        r1 = np.empty(shape=(self.num_particles,1))\n",
    "        r2 = np.empty(shape=(self.num_particles,1))\n",
    "        r_sigmoid = np.empty(shape=(self.num_particles,1))\n",
    "\n",
    "        for i in iterator:\n",
    "            #update random numbers\n",
    "            self.rng.random(size=(self.num_particles,1), out=r1)\n",
    "            self.rng.random(size=(self.num_particles,1), out=r2)\n",
    "            self.rng.random(size=(self.num_particles,1), out=r_sigmoid)\n",
    "\n",
    "            # update velocities\n",
    "            reduced_current_velocity = self.inertia * self.particle_velocities\n",
    "            local_velocity_component = self.c1 * r1 * (self.particle_best_pos - self.particle_positions)\n",
    "            global_velocity_component = self.c2 * r2 * (self.global_best_location - self.particle_positions)\n",
    "\n",
    "            new_velocity = reduced_current_velocity + local_velocity_component + global_velocity_component\n",
    "            self.particle_velocities = np.clip(new_velocity, a_max= self.max_velocity, a_min= self.min_velocity)\n",
    "\n",
    "            # update positions\n",
    "            #the original algorithm was flawed in regards to the position update\n",
    "            #see https://www.researchgate.net/publication/224302958_A_novel_binary_particle_swarm_optimization\n",
    "            sigmoid = 1/(1 + np.exp(-self.particle_velocities))\n",
    "            change_indices = r_sigmoid < sigmoid\n",
    "\n",
    "            #dimensions in which the normalised velocity value is greater than random value change their location value from 0 to 1 or vice versa\n",
    "            self.particle_positions[change_indices] == (self.particle_positions[change_indices] + 1) % 2\n",
    "\n",
    "            # calculate fitness\n",
    "            self.particle_fitness = self.compute_penalty_fitness(self.particle_positions, i)\n",
    "\n",
    "            # update best positions\n",
    "            # local best positions\n",
    "            new_best_local_fitness_indices = self.particle_fitness > self.particle_best_fitness\n",
    "            self.particle_best_fitness[new_best_local_fitness_indices] = self.particle_fitness[new_best_local_fitness_indices]\n",
    "            self.particle_best_pos[new_best_local_fitness_indices] = self.particle_positions[new_best_local_fitness_indices]\n",
    "\n",
    "            # global best positions\n",
    "            new_best_global_fitness = np.min(self.particle_fitness) #find best fitness value\n",
    "            new_best_global_fitness_indices = np.argwhere(self.particle_fitness == new_best_global_fitness) #find all particles that have the best fitness value\n",
    "            new_best_chosen_global_fitness_index = self.rng.choice(new_best_global_fitness_indices) #randomly choose one of the particles with the best fitness values\n",
    "\n",
    "            #update best solution \n",
    "            if new_best_global_fitness < self.global_best_fitness:\n",
    "                self.global_best_fitness = new_best_global_fitness\n",
    "                self.global_best_location = self.particle_positions[new_best_chosen_global_fitness_index].copy()\n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitness and penalty functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_covered_squares(particle_position: np.ndarray, binary_space: bool = True, board_size: int = None) -> np.ndarray:\n",
    "    ''' \n",
    "    Computes all covered squares given the position of a single particle. \n",
    "    Covered squares are defined as positions on the chessboard that are either occupied or attacked by a knight.\n",
    "    '''\n",
    "    if binary_space:\n",
    "        board_size = int(np.sqrt(particle_position.shape[0]))\n",
    "        particle_position = particle_position.reshape((board_size, board_size))\n",
    "    else:\n",
    "        assert board_size is not None, \"When using integer space, you have to specify the board_size parameter\"\n",
    "        particle_position = convert_integer_to_binary_space(particle_position, board_size)\n",
    "\n",
    "    knight_position_indices = np.argwhere(particle_position)\n",
    "\n",
    "    covered_positions = []\n",
    "    relative_jump_positions = [\n",
    "        #(x_change, y_change)\n",
    "        ( 0, 0),#current position\n",
    "        (-1,-2),#left top\n",
    "        (+1,-2),#left bottom\n",
    "        (-1,+2),#right top\n",
    "        (+1,+2),#right bottom\n",
    "        (-2,-1),#top left\n",
    "        (-2,+1),#top right\n",
    "        (+2,-1),#bottom left\n",
    "        (+2,+1),#bottom right\n",
    "    ]\n",
    "\n",
    "    for relative_jump_position in relative_jump_positions:\n",
    "        #calculate positions that the knights can jump to\n",
    "        positions = knight_position_indices.copy()\n",
    "        positions += relative_jump_position   \n",
    "\n",
    "        #calculated positions are only valid if they are within the bounds of the chessboard     \n",
    "        valid_indices = np.all((positions >= 0) & (positions < board_size), axis=1)\n",
    "\n",
    "        #append valid positions to the list of attacked positions\n",
    "        covered_positions.extend(positions[valid_indices])\n",
    "    \n",
    "    covered_positions = np.array(covered_positions)\n",
    "    unique_positions = np.unique(covered_positions, axis=0)\n",
    "\n",
    "    return unique_positions\n",
    "\n",
    "def convert_integer_to_binary_space(particle_position: np.ndarray, board_size: int):\n",
    "    binary_position = np.zeros(shape=(board_size, board_size)) #initialise board\n",
    "    knight_position_indices = np.cumsum(particle_position) #calculate knight positions on board\n",
    "    knight_position_indices = knight_position_indices - 1 #set the reference point for the first knight to -1 so that 0 always indicates an unused knight\n",
    "    \n",
    "    #keep only valid positions\n",
    "    valid_position_indices = knight_position_indices >= 0 & knight_position_indices < board_size**2 \n",
    "    knight_position_indices = knight_position_indices[valid_position_indices]\n",
    "\n",
    "    binary_position[knight_position_indices] = 1 #set knights on board\n",
    "    return binary_position\n",
    "\n",
    "\n",
    "def compute_num_of_covered_squares(particle_position: np.ndarray, binary_space: bool = True, board_size: int = None) -> int:\n",
    "    return compute_covered_squares(particle_position, binary_space, board_size).shape[0]\n",
    "\n",
    "\n",
    "a = np.array([0,1,1,0,0, \n",
    "              0,0,0,0,0, \n",
    "              0,0,1,0,1, \n",
    "              0,1,0,0,0,\n",
    "              1,0,0,0,0,])\n",
    "covered_squares = compute_covered_squares(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fitness function implementations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitness_binary_space_pso_paper(particle_positions: np.ndarray) -> np.ndarray:\n",
    "    '''From paper Investigating binary PSO parameter influence on the knights cover problem by N. Franken and A.P. Engelbrecht (2005)'''\n",
    "    num_covered_squares = np.apply_along_axis(compute_num_of_covered_squares, axis=1, arr = particle_positions)\n",
    "    num_knights = np.sum(particle_positions, axis=1)\n",
    "    total_num_squares = particle_positions.shape[1]\n",
    "    num_empty_squares = total_num_squares - num_covered_squares\n",
    "\n",
    "    fitness = num_empty_squares + num_knights + total_num_squares/num_covered_squares\n",
    "    return fitness\n",
    "\n",
    "def fitness_integer_space_pso_paper(particle_positions: np.ndarray, board_size:int = None) -> np.ndarray:\n",
    "    num_covered_squares = np.apply_along_axis(compute_num_of_covered_squares, axis=1, arr=particle_positions, binary_space=True, board_size=board_size)\n",
    "    num_knights = np.sum((particle_positions > 0), axis=1)\n",
    "    total_num_squares = board_size**2\n",
    "    num_empty_squares = total_num_squares - num_covered_squares\n",
    "\n",
    "    fitness = num_empty_squares + num_knights + total_num_squares/num_covered_squares\n",
    "    return fitness\n",
    "\n",
    "def fitness_binary_space_simple(particle_positions: np.ndarray) -> np.ndarray:\n",
    "    num_knights = np.sum(particle_positions, axis=1)\n",
    "    return num_knights\n",
    "\n",
    "def fitness_integer_space_simple(particle_positions: np.ndarray, board_size:int = None) -> np.ndarray:\n",
    "    num_knights = np.sum((particle_positions > 0), axis=1)\n",
    "    return num_knights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Penalty function implementations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#computes penalty for conventional search space depending on the ratio of empty squares\n",
    "def penalty_binary_space(particle_positions: np.ndarray, iteration_number: int):\n",
    "    ratio_of_empty_squares = (particle_positions.shape[1] - compute_num_of_covered_squares(particle_positions)) / particle_positions.shape[1]\n",
    "\n",
    "    penalties = iteration_number * ratio_of_empty_squares #use ratio so that the penalty is independent of the board size\n",
    "    return penalties\n",
    "\n",
    "#computes penalty for integer search space depending on ratio of empty squares and whether the knights are positioned outside the board\n",
    "def penalty_integer_space(particle_positions:np.ndarray, iteration_number: int, board_size):\n",
    "    ratio_of_empty_squares = (board_size**2 - compute_num_of_covered_squares(particle_positions)) / board_size**2\n",
    "    last_knight_location = np.sum(particle_positions, axis=1)\n",
    "    distance_from_last_square = last_knight_location - board_size**2\n",
    "\n",
    "    penalties = iteration_number * (ratio_of_empty_squares + np.maximum(0, distance_from_last_square))\n",
    "    return penalties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Search Algorithm class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomSearch:\n",
    "    def __init__(self, board_size: int, fitness_function: Callable[[np.ndarray], np.ndarray], \n",
    "                 penalty_function: Callable[[np.ndarray, int], np.ndarray] = (lambda _: 0), \n",
    "                 rng: np.random.Generator = np.random.default_rng(None)):\n",
    "        \n",
    "        self.board_size = board_size\n",
    "        self.fitness_function = fitness_function\n",
    "        self.penalty_function = penalty_function\n",
    "        self.rng = rng\n",
    "\n",
    "        self.current_solution = self.rng.integers(low=0, high=1, endpoint=True, size=board_size**2)\n",
    "        self.best_solution = self.current_solution.copy()\n",
    "        self.best_fitness = self.compute_penalty_fitness(self.best_solution, 0)\n",
    "        \n",
    "    def compute_penalty_fitness(self, particle_positions: np.ndarray, k: int):\n",
    "        ''' Computes the fitness subtracted by the penalty for invalid solutions (i.e. not all squares attacked or occupied).\n",
    "            The penalty function receives a parameter 'k', which indicates the current iteration number.\n",
    "        '''\n",
    "        return self.fitness_function(particle_positions) + self.penalty_function(particle_positions, k)\n",
    "        \n",
    "    def optimise(self, iterator):\n",
    "        for i in iterator:\n",
    "            #select random position to be altered\n",
    "            mutation_index = self.rng.integers(low=0, high=self.current_solution.shape[0])\n",
    "            #set element at index position to it's binary complement\n",
    "            self.current_solution[mutation_index] = (self.current_solution[mutation_index]+1) % 2 \n",
    "            #compute fitness of altered solution\n",
    "            fitness = self.compute_penalty_fitness(self.current_solution, i)\n",
    "            \n",
    "            #update best solution\n",
    "            if(fitness < self.best_fitness):\n",
    "                self.best_solution = self.current_solution.copy()\n",
    "                self.best_fitness = fitness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stochastic Hillclimb Algorithm class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#implements First choice stochastic hill climb as per Artificial Intelligence: A Modern Approach, Global Edition, Fourth Edition\n",
    "class StochasticHillclimb:\n",
    "    def __init__(self, board_size: int, fitness_function: Callable[[np.ndarray], np.ndarray], \n",
    "                 penalty_function: Callable[[np.ndarray, int], np.ndarray] = (lambda _: 0), allowed_plateau_steps: int = 100,\n",
    "                 rng: np.random.Generator = np.random.default_rng(None)):\n",
    "        \n",
    "        self.board_size = board_size\n",
    "        self.fitness_function = fitness_function\n",
    "        self.penalty_function = penalty_function\n",
    "        self.rng = rng\n",
    "        self.allowed_plateau_steps = allowed_plateau_steps\n",
    "\n",
    "        self.current_solution = self.rng.integers(low=0, high=1, endpoint=True, size=board_size**2)\n",
    "        self.current_fitness = self.compute_penalty_fitness(self.current_solution, 0)\n",
    "\n",
    "    def compute_penalty_fitness(self, particle_positions: np.ndarray, k: int):\n",
    "        ''' Computes the fitness subtracted by the penalty for invalid solutions (i.e. not all squares attacked or occupied).\n",
    "            The penalty function receives a parameter 'k', which indicates the current iteration number.\n",
    "        '''\n",
    "        return self.fitness_function(particle_positions) + self.penalty_function(particle_positions, k)\n",
    "\n",
    "    def optimise(self, iterator):\n",
    "        num_plateau_steps = 0\n",
    "\n",
    "        for i in iterator:\n",
    "            neighbour_permutation = self.rng.permutation(self.current_solution.shape[0])\n",
    "\n",
    "            for neighbour_index in neighbour_permutation:\n",
    "                neighbour_solution = self.current_solution.copy()\n",
    "                neighbour_solution[neighbour_index] = (neighbour_solution[neighbour_index]+1) % 2 \n",
    "                neighbour_fitness = self.compute_penalty_fitness(neighbour_fitness, i)\n",
    "\n",
    "                #choose first neighbour with more optimal fitness (in this case, lower fitness value as we want to minimise the function)\n",
    "                if neighbour_fitness <= self.current_fitness:\n",
    "                    #check if fintess is on a plateau\n",
    "                    if neighbour_fitness == self.current_fitness:\n",
    "                        num_plateau_steps += 1 #increment plateau step counter\n",
    "\n",
    "                        #cancel optimisation if maximum number of plateau steps is reached\n",
    "                        if num_plateau_steps > self.allowed_plateau_steps: return\n",
    "                        \n",
    "                    else: #reset plateau step counter if fitness is reduced\n",
    "                        num_plateau_steps = 0\n",
    "\n",
    "                    self.current_solution = neighbour_solution\n",
    "                    self.current_fitness = neighbour_fitness\n",
    "                    break #dont consider the remaining neighbours\n",
    "            \n",
    "                return # no improved solution was found among the neighbours -> peak has been reached"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def increment_indices(current_indices, max_indices):\n",
    "    current_indices[-1] += 1\n",
    "    for i in reversed(range(len(current_indices))):\n",
    "        if current_indices[i] > max_indices[i]:\n",
    "            current_indices[i] = 0\n",
    "            if i != 0:\n",
    "                current_indices[i-1] +=1\n",
    "        else:\n",
    "            break\n",
    "    return current_indices\n",
    "\n",
    "def fetch_algorithm_parameters(algorithm_config, parameter_indices):\n",
    "    config_value_list = list(algorithm_config.values())\n",
    "    parameters = [config_value_list[parameter][parameter_index] for parameter, parameter_index in enumerate(parameter_indices)]\n",
    "    \n",
    "    #flatten tuples in parameter list\n",
    "    flattened_parameters = []\n",
    "    for element in parameters:\n",
    "        if isinstance(element,tuple):\n",
    "            flattened_parameters.extend(element)\n",
    "        else:\n",
    "            flattened_parameters.append(element)\n",
    "            \n",
    "    return flattened_parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimentation config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run configuration for particle swarm optimisation\n",
    "pso_config = {\n",
    "    \"fitness_and_penalty_functions\": [(fitness_binary_space_pso_paper,None)],\n",
    "    \"num_particles\": [100],\n",
    "    \"c1_c2_and_inertia\": [(1,1,1)],\n",
    "    \"max_min_velocity\": [(4,-4)],\n",
    "}\n",
    "\n",
    "#run configuration for random search\n",
    "rs_config = {\n",
    "    \"fitness_and_penalty_functions\": [(),()]\n",
    "}\n",
    "\n",
    "#run configuration for stochastic hillclimb\n",
    "shc_config = {\n",
    "    \"fitness_and_penalty_functions\": [(),()],\n",
    "    \"allowed_plateau_steps\": []\n",
    "}\n",
    "\n",
    "#meta run config for all experiments\n",
    "run_config = {\n",
    "    \"optimisation_algorithm\": [PSO, RandomSearch, StochasticHillclimb],\n",
    "    \"algorithm_configs\":[pso_config, rs_config, shc_config],\n",
    "    \"board_sizes\": list(np.arange(start=4, stop=25)),\n",
    "    \"runs_per_experiment\": 10,\n",
    "    \"iterations_per_run\": 100,\n",
    "    \"rng_seed\": 1234567\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca0f876454f2427c8dcae37bdabfea9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optimisation Algorithms:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db532ec91ab7455fb1f88acadb628609",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Experiments:   0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f59d39479ab4a83811b34b100209bf5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Runs:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75ccca53dcc24582b74c405afbec81cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Runs:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee0ca384dd8f4a6c91e3e5b94ad4d1fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Runs:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "805117a85a3b4bb19abeb041b248c27d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Runs:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "986ac48a1d6e4cb48a1e67c10de8c6f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Runs:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0940a93871d04e349cc6157a8f89b630",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Runs:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 29\u001b[0m\n\u001b[1;32m     27\u001b[0m     optimiser \u001b[38;5;241m=\u001b[39m algorithm(\u001b[38;5;241m*\u001b[39mparameters) \u001b[38;5;66;03m#initialise optimisation algorithm with parameters\u001b[39;00m\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;66;03m#iterator = tqdm(range(run_config[\"iterations_per_run\"]), desc=\"Iterations\", position=3, leave=False)\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m     \u001b[43moptimiser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimise\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mrun_config\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43miterations_per_run\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m#perform optimisation\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m#increment indices of the current algorithm's parameters\u001b[39;00m\n\u001b[1;32m     31\u001b[0m current_parameter_indices \u001b[38;5;241m=\u001b[39m increment_indices(current_parameter_indices, max_parameter_indices)\n",
      "Cell \u001b[0;32mIn[3], line 84\u001b[0m, in \u001b[0;36mPSO.optimise\u001b[0;34m(self, num_iterations)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparticle_positions[change_indices] \u001b[38;5;241m==\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparticle_positions[change_indices] \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;66;03m# calculate fitness\u001b[39;00m\n\u001b[0;32m---> 84\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparticle_fitness \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_penalty_fitness\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparticle_positions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;66;03m# update best positions\u001b[39;00m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;66;03m# local best positions\u001b[39;00m\n\u001b[1;32m     88\u001b[0m new_best_local_fitness_indices \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparticle_fitness \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparticle_best_fitness\n",
      "Cell \u001b[0;32mIn[3], line 48\u001b[0m, in \u001b[0;36mPSO.compute_penalty_fitness\u001b[0;34m(self, particle_positions, k)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_penalty_fitness\u001b[39m(\u001b[38;5;28mself\u001b[39m, particle_positions: np\u001b[38;5;241m.\u001b[39mndarray, k: \u001b[38;5;28mint\u001b[39m):\n\u001b[1;32m     45\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m''' Computes the fitness subtracted by the penalty for invalid solutions (i.e. not all squares attacked or occupied).\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;124;03m        The penalty function receives a parameter 'k', which indicates the current iteration number.\u001b[39;00m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[0;32m---> 48\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfitness_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparticle_positions\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpenalty_function(particle_positions, k)\n",
      "Cell \u001b[0;32mIn[5], line 3\u001b[0m, in \u001b[0;36mfitness_binary_space_pso_paper\u001b[0;34m(particle_positions)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfitness_binary_space_pso_paper\u001b[39m(particle_positions: np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[1;32m      2\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''From paper Investigating binary PSO parameter influence on the knights cover problem by N. Franken and A.P. Engelbrecht (2005)'''\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m     num_covered_squares \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_along_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompute_num_of_covered_squares\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marr\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mparticle_positions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     num_knights \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(particle_positions, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      5\u001b[0m     total_num_squares \u001b[38;5;241m=\u001b[39m particle_positions\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/numpy/lib/shape_base.py:402\u001b[0m, in \u001b[0;36mapply_along_axis\u001b[0;34m(func1d, axis, arr, *args, **kwargs)\u001b[0m\n\u001b[1;32m    400\u001b[0m buff[ind0] \u001b[38;5;241m=\u001b[39m res\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ind \u001b[38;5;129;01min\u001b[39;00m inds:\n\u001b[0;32m--> 402\u001b[0m     buff[ind] \u001b[38;5;241m=\u001b[39m asanyarray(\u001b[43mfunc1d\u001b[49m\u001b[43m(\u001b[49m\u001b[43minarr_view\u001b[49m\u001b[43m[\u001b[49m\u001b[43mind\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    404\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(res, matrix):\n\u001b[1;32m    405\u001b[0m     \u001b[38;5;66;03m# wrap the array, to preserve subclasses\u001b[39;00m\n\u001b[1;32m    406\u001b[0m     buff \u001b[38;5;241m=\u001b[39m res\u001b[38;5;241m.\u001b[39m__array_wrap__(buff)\n",
      "Cell \u001b[0;32mIn[4], line 59\u001b[0m, in \u001b[0;36mcompute_num_of_covered_squares\u001b[0;34m(particle_position, binary_space, board_size)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_num_of_covered_squares\u001b[39m(particle_position: np\u001b[38;5;241m.\u001b[39mndarray, binary_space: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m, board_size: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mint\u001b[39m:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcompute_covered_squares\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparticle_position\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbinary_space\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mboard_size\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n",
      "Cell \u001b[0;32mIn[4], line 38\u001b[0m, in \u001b[0;36mcompute_covered_squares\u001b[0;34m(particle_position, binary_space, board_size)\u001b[0m\n\u001b[1;32m     35\u001b[0m     valid_indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mall((positions \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m&\u001b[39m (positions \u001b[38;5;241m<\u001b[39m board_size), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;66;03m#append valid positions to the list of attacked positions\u001b[39;00m\n\u001b[0;32m---> 38\u001b[0m     \u001b[43mcovered_positions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpositions\u001b[49m\u001b[43m[\u001b[49m\u001b[43mvalid_indices\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m covered_positions \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(covered_positions)\n\u001b[1;32m     41\u001b[0m unique_positions \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(covered_positions, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#TODO: switch from iterations to fitness function evaluations for PSO\n",
    "#TODO: store results in numpy array and then to pandas dataframe\n",
    "rng = np.random.default_rng(run_config[\"rng_seed\"])\n",
    "\n",
    "# run each optimisation algorithm\n",
    "for optimiser_id, algorithm in tqdm(enumerate(run_config[\"optimisation_algorithm\"]), \n",
    "    desc=\"Optimisation Algorithms\", total=len(run_config[\"optimisation_algorithm\"]), position=0, leave=False):\n",
    "\n",
    "    algorithm_config = run_config[\"algorithm_configs\"][optimiser_id] #fetch experiment config for the current optimisation algorithm\n",
    "    \n",
    "    #add board_sizes from run_config as first element of current config\n",
    "    extended_config = {\"board_sizes\":run_config[\"board_sizes\"]} \n",
    "    extended_config.update(algorithm_config)\n",
    "    algorithm_config = extended_config\n",
    "\n",
    "    max_parameter_indices = np.array([len(x)-1 for x in algorithm_config.values()], dtype=int) #compute the maximum indices for each config parameter\n",
    "    num_of_experiments = np.cumprod(max_parameter_indices + 1)[-1] #compute the number of experiments to run based on number of values in config\n",
    "    current_parameter_indices = np.zeros(len(algorithm_config), dtype= int) #initialise current parameter indices to 0\n",
    "\n",
    "    #run all experiments\n",
    "    for experiment_index in tqdm(range(num_of_experiments), desc=\"Experiments\", position=1, leave=False):\n",
    "        parameters = fetch_algorithm_parameters(algorithm_config, current_parameter_indices)\n",
    "        parameters.append(rng) #append random number generator to parameters\n",
    "\n",
    "        #run all runs of the same experiment\n",
    "        for run in tqdm(range(run_config[\"runs_per_experiment\"]), desc=\"Runs\", position=2, leave=False):\n",
    "            optimiser = algorithm(*parameters) #initialise optimisation algorithm with parameters\n",
    "            iterator = tqdm(range(run_config[\"iterations_per_run\"]), desc=\"Iterations\", position=3, leave=False)\n",
    "            optimiser.optimise(iterator) #perform optimisation\n",
    "        #increment indices of the current algorithm's parameters\n",
    "        current_parameter_indices = increment_indices(current_parameter_indices, max_parameter_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store experiment results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result Visualisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load results file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
