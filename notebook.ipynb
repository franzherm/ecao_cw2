{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Particle Swarm Optimisation for Knights Covering Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#necessary python library imports\n",
    "import numpy as np\n",
    "from collections.abc import Callable\n",
    "from tqdm.auto import tqdm\n",
    "import itertools\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Particle Swarm Optimisation class\n",
    "\n",
    "Fitness function is an error function, so we want to minimise it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def none_value_wrapper(value, default):\n",
    "    if value is None:\n",
    "        value = default\n",
    "    return value\n",
    "\n",
    "#features are number of fitness evaluations, fitness value, number of knights, number of covered squares.\n",
    "def store_iteration_results(result_array, index, num_fitness_evals, fitness_value, solution, binary_space: bool = True, board_size = None):\n",
    "    num_covered_squares = 0\n",
    "    if not binary_space:\n",
    "        num_covered_squares = compute_num_of_covered_squares(solution, binary_space= False, board_size=board_size)\n",
    "    else:\n",
    "        num_covered_squares = compute_num_of_covered_squares(solution)\n",
    "    num_knights = np.sum(solution != 0)\n",
    "    \n",
    "    result_array[index,:] = np.array([num_fitness_evals, fitness_value, num_knights, num_covered_squares])\n",
    "\n",
    "def compute_covered_squares(particle_position: np.ndarray, binary_space: bool = True, board_size: int = None) -> np.ndarray:\n",
    "    ''' \n",
    "    Computes all covered squares given the position of a single particle. \n",
    "    Covered squares are defined as positions on the chessboard that are either occupied or attacked by a knight.\n",
    "    '''\n",
    "    if binary_space:\n",
    "        board_size = int(np.sqrt(np.prod(particle_position.shape)))\n",
    "    else:\n",
    "        assert board_size is not None, \"When using integer space, you have to specify the board_size parameter\"\n",
    "        particle_position = convert_integer_to_binary_space(particle_position, board_size)\n",
    "\n",
    "    particle_position = particle_position.reshape((board_size, board_size))\n",
    "    knight_position_indices = np.argwhere(particle_position)\n",
    "\n",
    "    covered_positions = []\n",
    "    relative_jump_positions = [\n",
    "        #(x_change, y_change)\n",
    "        ( 0, 0),#current position\n",
    "        (-1,-2),#left top\n",
    "        (+1,-2),#left bottom\n",
    "        (-1,+2),#right top\n",
    "        (+1,+2),#right bottom\n",
    "        (-2,-1),#top left\n",
    "        (-2,+1),#top right\n",
    "        (+2,-1),#bottom left\n",
    "        (+2,+1),#bottom right\n",
    "    ]\n",
    "\n",
    "    for relative_jump_position in relative_jump_positions:\n",
    "        #calculate positions that the knights can jump to\n",
    "        positions = knight_position_indices.copy()\n",
    "        positions += relative_jump_position   \n",
    "\n",
    "        #calculated positions are only valid if they are within the bounds of the chessboard     \n",
    "        valid_indices = np.all((positions >= 0) & (positions < board_size), axis=1)\n",
    "\n",
    "        #append valid positions to the list of attacked positions\n",
    "        covered_positions.extend(positions[valid_indices])\n",
    "    \n",
    "    covered_positions = np.array(covered_positions)\n",
    "    unique_positions = np.unique(covered_positions, axis=0)\n",
    "\n",
    "    return unique_positions\n",
    "\n",
    "def convert_integer_to_binary_space(particle_position: np.ndarray, board_size: int):\n",
    "    binary_position = np.zeros(shape=board_size**2, dtype=np.uint8) #initialise board\n",
    "    knight_position_indices = np.cumsum(particle_position, dtype=np.uint32) #calculate knight positions on board\n",
    "    knight_position_indices = knight_position_indices - 1 #set the reference point for the first knight to -1 so that 0 always indicates an unused knight\n",
    "    \n",
    "    #keep only valid positions\n",
    "    valid_position_indices = (knight_position_indices >= 0) & (knight_position_indices < board_size**2)\n",
    "    knight_position_indices = knight_position_indices[valid_position_indices]\n",
    "\n",
    "    binary_position[knight_position_indices] = 1 #set knights on board\n",
    "    return binary_position\n",
    "\n",
    "def convert_binary_to_integer_space(particle_position: np.ndarray, max_number_of_knights):\n",
    "    knight_positions = np.argwhere(particle_position == 1).flatten()\n",
    "    num_knights = knight_positions.shape[0]\n",
    "\n",
    "    relative_positions = knight_positions.copy()\n",
    "    relative_positions[1:] -= relative_positions[:-1].copy() #inverse of cumsum as per https://stackoverflow.com/questions/38666924/what-is-the-inverse-of-the-numpy-cumsum-function\n",
    "    binary_positions = np.zeros(max_number_of_knights, dtype=np.uint32)\n",
    "\n",
    "    #store integer positions in return array\n",
    "    if num_knights > max_number_of_knights:\n",
    "        binary_positions[:max_number_of_knights] = relative_positions[:max_number_of_knights]\n",
    "    else:\n",
    "        binary_positions[:num_knights] = relative_positions[:num_knights]\n",
    "\n",
    "    binary_positions[0] = binary_positions[0] + 1 # reference point for first cell is the imaginary cell with index -1\n",
    "    return binary_positions\n",
    "\n",
    "\n",
    "def compute_num_of_covered_squares(particle_position: np.ndarray, binary_space: bool = True, board_size: int = None) -> int:\n",
    "    return compute_covered_squares(particle_position, binary_space, board_size).shape[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Algorithm implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PSO:\n",
    "    def __init__(self, board_size: int, binary_space: bool, fitness_function: Callable[[np.ndarray], np.ndarray], \n",
    "                 penalty_function: Callable[[np.ndarray, int], np.ndarray] = (lambda *x: 0), num_particles: int = 100, c1: float = 1.0, \n",
    "                 c2: float = 1.0, inertia: float = 1.0, max_velocity: float = 4.0, min_velocity: float = -4.0, \n",
    "                 rng: np.random.Generator = np.random.default_rng(None)) -> None:\n",
    "        \n",
    "        #check for sensible hyperparameter selection\n",
    "        assert min_velocity < max_velocity, \"Max velocity has to be greater than the min velocity.\" \n",
    "        assert num_particles > 1, \"There has to be at least one particle\"\n",
    "        assert c1 >= 0, \"c1 has to be greater than 0\"\n",
    "        assert c2 >= 0, \"c2 has to be greater than 0\"\n",
    "        assert board_size > 3, \"board size has to be at least 3\"\n",
    "\n",
    "        #assign hyperparameters to object variables\n",
    "\n",
    "        #condition on sensible inertia values as proposed in: \"F. van den Bergh. An Analysis of Particle Swarm Optimizers (2002)\"\n",
    "        if isinstance(inertia, tuple):\n",
    "            self.inertia = inertia[0]\n",
    "            self.max_inertia = inertia[0]\n",
    "            self.min_inertia = inertia[1]\n",
    "            assert self.min_inertia >= 0 and self.inertia > self.min_inertia, \"min inertia must be greater or equal to zero and less than initial inertia\"\n",
    "        else:\n",
    "            assert inertia > c1+c2 / 2 - 1 and inertia >= 0, \"Inertia must be positive and greater than (c1 + c2) / 2 -1\"\n",
    "            self.inertia = none_value_wrapper(inertia, default=1.0)\n",
    "\n",
    "        self.board_size = board_size\n",
    "        self.binary_space = binary_space\n",
    "        self.fitness_function = fitness_function\n",
    "        self.penalty_function = none_value_wrapper(penalty_function, default=(lambda *x: 0))\n",
    "        self.num_particles = none_value_wrapper(num_particles, default=100)\n",
    "        self.c1 = none_value_wrapper(c1, default=1.0)\n",
    "        self.c2 = none_value_wrapper(c2, default=1.0)\n",
    "        self.max_velocity = none_value_wrapper(max_velocity,4.0)\n",
    "        self.min_velocity = none_value_wrapper(min_velocity,-4.0)\n",
    "        self.rng = none_value_wrapper(rng, np.random.default_rng(None))\n",
    "\n",
    "        #initialise particles and velocities\n",
    "        self.particle_positions = self.initialise_particle_positions(self.num_particles,self.binary_space, self.board_size)\n",
    "        self.particle_best_pos = self.particle_positions.copy()\n",
    "        \n",
    "        #set initial velocity to be in range [min_velocity, max_velocity]\n",
    "        random_velocities_factors = self.rng.random(size=(self.num_particles, self.particle_positions.shape[1]))\n",
    "        self.particle_velocities = random_velocities_factors * (self.max_velocity - self.min_velocity) + self.min_velocity\n",
    "        \n",
    "        #initialise global best\n",
    "        self.particle_fitness = self.compute_penalty_fitness(self.particle_positions, 0, self.binary_space, self.board_size)\n",
    "        self.particle_best_fitness = self.particle_fitness.copy()\n",
    "\n",
    "        best_fitness = np.min(self.particle_fitness) #find best fitness value\n",
    "        best_indices = np.argwhere(self.particle_fitness == best_fitness) #find all particles that have the best fitness value\n",
    "        best_chosen_index = self.rng.choice(best_indices) #randomly choose one of the particles with the best fitness values\n",
    "\n",
    "        self.global_best_location = self.particle_positions[best_chosen_index].copy()\n",
    "        self.global_best_fitness = self.particle_fitness[best_chosen_index][0]\n",
    "    \n",
    "    def initialise_particle_positions(self, num_particles: int, binary_space: bool, board_size: int):\n",
    "        initial_positions = None\n",
    "        if binary_space: #for binary space\n",
    "            initial_positions = self.rng.integers(low=0, high=1, endpoint=True, size=(num_particles, board_size**2))\n",
    "\n",
    "        else: #for integer space\n",
    "            #formular for maximum number of knights as described in: https://mathworld.wolfram.com/KnightsProblem.html\n",
    "            max_num_of_knights = (board_size**2)/2\n",
    "            if board_size % 2 == 1:\n",
    "                max_num_of_knights += 0.5\n",
    "            max_num_of_knights = int(max_num_of_knights)\n",
    "\n",
    "            chess_boards = np.zeros(shape=(num_particles, board_size**2), dtype=np.uint8)\n",
    "            num_knights = self.rng.integers(low=1, high=max_num_of_knights,endpoint=True, size=num_particles)\n",
    "            indices = [self.rng.choice(board_size**2, size=x, replace=False) for x in num_knights]\n",
    "            \n",
    "            for i in range(len(indices)):\n",
    "                chess_boards[i,indices[i]] = 1\n",
    "\n",
    "            initial_positions = np.apply_along_axis(convert_binary_to_integer_space, axis=1,arr=chess_boards,max_number_of_knights=max_num_of_knights)\n",
    "\n",
    "\n",
    "        return initial_positions\n",
    "\n",
    "    def compute_penalty_fitness(self, particle_positions: np.ndarray, k: int, binary_space: bool, board_size:int):\n",
    "        ''' Computes the fitness subtracted by the penalty for invalid solutions (i.e. not all squares attacked or occupied).\n",
    "            The penalty function receives a parameter 'k', which indicates the current iteration number.\n",
    "        '''\n",
    "        if binary_space:\n",
    "            return self.fitness_function(particle_positions) + self.penalty_function(particle_positions, k)\n",
    "        else:\n",
    "            return self.fitness_function(particle_positions, board_size) + self.penalty_function(particle_positions, k, board_size)\n",
    "    \n",
    "    def update_locations(self, r_sigmoid, binary_space):\n",
    "        if binary_space:\n",
    "            #the original algorithm was flawed in regards to the position update\n",
    "            #see https://www.researchgate.net/publication/224302958_A_novel_binary_particle_swarm_optimization\n",
    "            sigmoid = 1/(1 + np.exp(-self.particle_velocities))\n",
    "            change_indices = r_sigmoid < sigmoid\n",
    "\n",
    "            #dimensions in which the normalised velocity value is greater than random value change their location value from 0 to 1 or vice versa\n",
    "            self.particle_positions[change_indices] = (self.particle_positions[change_indices] + 1) % 2\n",
    "\n",
    "        else:\n",
    "            #adds velocity to current position. Rounds to nearest integer and clips so that the numbers are always non-negative.\n",
    "            new_positions = np.clip(np.rint(self.particle_positions + self.particle_velocities),a_min=0, a_max=self.board_size**2)\n",
    "            \n",
    "            new_positions_array = np.zeros(shape=self.particle_positions.shape)\n",
    "            non_zero_indices = new_positions != 0\n",
    "\n",
    "            #shifts the zeros to the end of the rows while maintaining the relative order of all the other elements in the row\n",
    "            for i, row in enumerate(new_positions):\n",
    "                non_zero_elements = row[non_zero_indices[i]]\n",
    "                new_positions_array[i,:len(non_zero_elements)] = non_zero_elements\n",
    "            \n",
    "            #update particle positions array\n",
    "            self.particle_positions = new_positions_array\n",
    "\n",
    "    def optimise(self, num_fitness_evaluations):\n",
    "        ''' Starts the optimisation loop. The num_iterations parameter specifies the terimination criterion as \n",
    "            the number of iterations that will be done.\n",
    "        '''\n",
    "        num_iterations = (num_fitness_evaluations // self.num_particles)+1\n",
    "\n",
    "        #features are number of fitness evaluations, fitness value, number of knights, number of covered squares.\n",
    "        #Only current best solutions are stored\n",
    "        metric_results = np.full(shape=(num_iterations, 4), fill_value=-1, dtype=np.float64)\n",
    "        stored_solutions = []\n",
    "\n",
    "        store_iteration_results(metric_results, index=0, num_fitness_evals=0, fitness_value=self.global_best_fitness,\n",
    "                                solution=self.global_best_location, binary_space=self.binary_space, board_size=self.board_size)\n",
    "        stored_solutions.append(self.global_best_location if self.binary_space \n",
    "                                else convert_integer_to_binary_space(self.global_best_location,self.board_size))\n",
    "\n",
    "\n",
    "        # initialise random numbers used in velocity computation\n",
    "        r1 = np.empty(shape=(self.num_particles,1))\n",
    "        r2 = np.empty(shape=(self.num_particles,1))\n",
    "        r_sigmoid = np.empty(shape=(self.num_particles,1))\n",
    "\n",
    "        for i in range(1, num_iterations):\n",
    "            #update random numbers\n",
    "            self.rng.random(size=(self.num_particles,1), out=r1)\n",
    "            self.rng.random(size=(self.num_particles,1), out=r2)\n",
    "            self.rng.random(size=(self.num_particles,1), out=r_sigmoid)\n",
    "\n",
    "            # update velocities\n",
    "            reduced_current_velocity = self.inertia * self.particle_velocities\n",
    "            local_velocity_component = self.c1 * r1 * (self.particle_best_pos - self.particle_positions)\n",
    "            global_velocity_component = self.c2 * r2 * (self.global_best_location - self.particle_positions)\n",
    "\n",
    "            new_velocity = reduced_current_velocity + local_velocity_component + global_velocity_component\n",
    "            self.particle_velocities = np.clip(new_velocity, a_max= self.max_velocity, a_min= self.min_velocity)\n",
    "\n",
    "            # update positions of particles in place\n",
    "            self.update_locations(r_sigmoid, binary_space=self.binary_space)\n",
    "\n",
    "            #linearly decrease inertia value according to: https://ieeexplore.ieee.org/document/6089659\n",
    "            if hasattr(self, 'min_inertia'):\n",
    "                self.inertia = self.max_inertia - i * (self.max_inertia - self.min_inertia)/(num_iterations-1)\n",
    "\n",
    "            # calculate fitness\n",
    "            self.particle_fitness = self.compute_penalty_fitness(self.particle_positions, i, self.binary_space, self.board_size)\n",
    "\n",
    "            # update best positions\n",
    "            # local best positions\n",
    "            new_best_local_fitness_indices = self.particle_fitness > self.particle_best_fitness\n",
    "            self.particle_best_fitness[new_best_local_fitness_indices] = self.particle_fitness[new_best_local_fitness_indices]\n",
    "            self.particle_best_pos[new_best_local_fitness_indices] = self.particle_positions[new_best_local_fitness_indices]\n",
    "\n",
    "            # global best positions\n",
    "            new_best_global_fitness = np.min(self.particle_fitness) #find best fitness value\n",
    "            new_best_global_fitness_indices = np.argwhere(self.particle_fitness == new_best_global_fitness) #find all particles that have the best fitness value\n",
    "            new_best_chosen_global_fitness_index = self.rng.choice(new_best_global_fitness_indices) #randomly choose one of the particles with the best fitness values\n",
    "\n",
    "            #update best solution \n",
    "            if new_best_global_fitness < self.global_best_fitness:\n",
    "                self.global_best_fitness = new_best_global_fitness\n",
    "                self.global_best_location = self.particle_positions[new_best_chosen_global_fitness_index].copy()\n",
    "            \n",
    "            #store solution and metric values to arrays\n",
    "            store_iteration_results(metric_results, index=i, num_fitness_evals=i*self.num_particles, fitness_value=self.global_best_fitness,\n",
    "                                    solution=self.global_best_location, binary_space=self.binary_space, board_size=self.board_size)\n",
    "            stored_solutions.append(self.global_best_location if self.binary_space else convert_integer_to_binary_space(self.global_best_location, board_size=self.board_size))\n",
    "        \n",
    "        return metric_results, stored_solutions\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitness and penalty functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fitness function implementations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitness_space_pso_paper(particle_positions: np.ndarray, board_size:int = None) -> np.ndarray:\n",
    "    '''From paper Investigating binary PSO parameter influence on the knights cover problem by N. Franken and A.P. Engelbrecht (2005)'''\n",
    "\n",
    "    if board_size is not None:\n",
    "        return fitness_integer_space_pso_paper(particle_positions, board_size)\n",
    "    else:\n",
    "        num_covered_squares = np.apply_along_axis(compute_num_of_covered_squares, axis=1, arr = particle_positions)\n",
    "        num_knights = np.sum(particle_positions, axis=1)\n",
    "        total_num_squares = particle_positions.shape[1]\n",
    "        num_empty_squares = total_num_squares - num_covered_squares\n",
    "        \n",
    "        eps = 1e-6 #to avoid zero division\n",
    "        fitness = num_empty_squares + num_knights + (total_num_squares+eps)/(num_covered_squares + eps)\n",
    "\n",
    "        return fitness\n",
    "\n",
    "def fitness_integer_space_pso_paper(particle_positions: np.ndarray, board_size:int = None) -> np.ndarray:\n",
    "    num_covered_squares = np.apply_along_axis(compute_num_of_covered_squares, axis=1, arr=particle_positions, binary_space=False, board_size=board_size)\n",
    "    num_knights = np.sum((particle_positions > 0), axis=1)\n",
    "    total_num_squares = board_size**2\n",
    "    num_empty_squares = total_num_squares - num_covered_squares\n",
    "   \n",
    "    eps = 1e-6 #to avoid zero division\n",
    "    \n",
    "    fitness = num_empty_squares + num_knights + total_num_squares/(num_covered_squares + eps)\n",
    "    return fitness\n",
    "\n",
    "#this function works for both integer and binary search space\n",
    "def fitness_simple(particle_positions: np.ndarray, board_size: int = None) -> np.ndarray:\n",
    "    #binary space\n",
    "    ratio_of_empty_squares = None\n",
    "    if board_size is None:\n",
    "        ratio_of_empty_squares = (particle_positions.shape[1] - np.apply_along_axis(compute_num_of_covered_squares, axis = 1, arr=particle_positions)) \\\n",
    "                              / particle_positions.shape[1]\n",
    "    #integer space\n",
    "    else:  \n",
    "        ratio_of_empty_squares = (board_size**2 - np.apply_along_axis(compute_num_of_covered_squares, axis = 1, arr=particle_positions, binary_space=False, board_size=board_size)) \\\n",
    "                              / board_size**2\n",
    "    \n",
    "    ratio_of_empty_squares = ratio_of_empty_squares.astype(dtype=np.float64)\n",
    "    return ratio_of_empty_squares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Penalty function implementations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function wrapper that can deal with both search spaces\n",
    "def penalty_function(particle_positions: np.ndarray, iteration_number: int, board_size: int = None):\n",
    "    if board_size is None:\n",
    "        return penalty_binary_space(particle_positions, iteration_number)\n",
    "    else:\n",
    "        return penalty_integer_space(particle_positions, iteration_number, board_size)\n",
    "\n",
    "\n",
    "#computes penalty for conventional search space depending on the ratio of empty squares\n",
    "def penalty_binary_space(particle_positions: np.ndarray, iteration_number: int):\n",
    "    num_knights = np.sum((particle_positions > 0), axis=1, dtype=np.float64)\n",
    "    ratio_of_knights = num_knights / particle_positions.shape[0]\n",
    "    return ratio_of_knights\n",
    "\n",
    "#computes penalty for integer search space depending on ratio of empty squares and whether the knights are positioned outside the board\n",
    "def penalty_integer_space(particle_positions:np.ndarray, iteration_number: int, board_size):\n",
    "    last_knight_location = np.sum(particle_positions, axis=1, dtype=np.float64)\n",
    "    distance_from_last_square = last_knight_location - board_size**2\n",
    "    num_knights = np.sum((particle_positions > 0), axis=1)\n",
    "    ratio_of_knights = num_knights / board_size**2\n",
    "    penalties = ratio_of_knights + np.sqrt(iteration_number) * np.maximum(0, distance_from_last_square**2)\n",
    "    return penalties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Search Algorithm class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomSearch:\n",
    "    def __init__(self, board_size: int, fitness_function: Callable[[np.ndarray], np.ndarray], \n",
    "                 penalty_function: Callable[[np.ndarray, int], np.ndarray] = (lambda *x: 0), \n",
    "                 rng: np.random.Generator = np.random.default_rng(None)):\n",
    "        \n",
    "        self.board_size = board_size\n",
    "        self.fitness_function = fitness_function\n",
    "        self.penalty_function = none_value_wrapper(penalty_function, default=(lambda *x: 0))\n",
    "        self.rng = rng\n",
    "\n",
    "        self.current_solution = self.rng.integers(low=0, high=1, endpoint=True, size=board_size**2)\n",
    "        #add another dimension so that fitness functions work the same across all algorithms\n",
    "        self.current_solution = self.current_solution[np.newaxis,:]\n",
    "        self.best_solution = self.current_solution.copy()\n",
    "        self.best_fitness = self.compute_penalty_fitness(self.best_solution, 0)[0]\n",
    "        \n",
    "    def compute_penalty_fitness(self, particle_positions: np.ndarray, k: int):\n",
    "        ''' Computes the fitness subtracted by the penalty for invalid solutions (i.e. not all squares attacked or occupied).\n",
    "            The penalty function receives a parameter 'k', which indicates the current iteration number.\n",
    "        '''\n",
    "        \n",
    "        return self.fitness_function(particle_positions) + self.penalty_function(particle_positions, k)\n",
    "        \n",
    "    def optimise(self, num_iterations):\n",
    "        \n",
    "        #features are number of fitness evaluations, fitness value, number of knights, number of covered squares.\n",
    "        #Only current best solutions are stored\n",
    "        metric_results = np.full(shape=(num_iterations, 4), fill_value=-1, dtype=np.float64)\n",
    "        stored_solutions = []\n",
    "\n",
    "        store_iteration_results(metric_results, index=0, num_fitness_evals=0, fitness_value=self.best_fitness,solution=self.best_solution)\n",
    "        stored_solutions.append(self.best_solution)\n",
    "\n",
    "        for i in range(1, num_iterations):\n",
    "            #select random position to be altered\n",
    "            mutation_index = self.rng.integers(low=0, high=self.current_solution.shape[0])\n",
    "            #set element at index position to it's binary complement\n",
    "            self.current_solution[mutation_index] = (self.current_solution[mutation_index]+1) % 2 \n",
    "            #compute fitness of altered solution\n",
    "            fitness = self.compute_penalty_fitness(self.current_solution, i)[0]\n",
    "            \n",
    "            #update best solution\n",
    "            if(fitness < self.best_fitness):\n",
    "                self.best_solution = self.current_solution.copy()\n",
    "                self.best_fitness = fitness\n",
    "            \n",
    "            store_iteration_results(metric_results, index=i, num_fitness_evals=i, fitness_value=self.best_fitness, solution=self.best_solution)\n",
    "            stored_solutions.append(self.best_solution)\n",
    "        \n",
    "        return metric_results, stored_solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stochastic Hillclimb Algorithm class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#implements First choice stochastic hill climb as per Artificial Intelligence: A Modern Approach, Global Edition, Fourth Edition\n",
    "class StochasticHillclimb:\n",
    "    def __init__(self, board_size: int, fitness_function: Callable[[np.ndarray], np.ndarray], \n",
    "                 penalty_function: Callable[[np.ndarray, int], np.ndarray] = (lambda *x: 0), allowed_plateau_steps: int = 100,\n",
    "                 plateau_tolerance: float = 0.1, rng: np.random.Generator = np.random.default_rng(None)):\n",
    "        \n",
    "        assert plateau_tolerance >= 0\n",
    "\n",
    "        self.board_size = board_size\n",
    "        self.fitness_function = fitness_function\n",
    "        self.penalty_function = none_value_wrapper(penalty_function, default=(lambda *x: 0))\n",
    "        self.rng = rng\n",
    "        self.allowed_plateau_steps = allowed_plateau_steps\n",
    "        self.plateau_tolerance = plateau_tolerance\n",
    "        self.current_solution = self.rng.integers(low=0, high=1, endpoint=True, size=board_size**2)\n",
    "\n",
    "        #add another dimension so that fitness functions work the same across all algorithms\n",
    "        self.current_fitness = self.compute_penalty_fitness(self.current_solution[np.newaxis,:], 0)[0]\n",
    "\n",
    "    def compute_penalty_fitness(self, particle_positions: np.ndarray, k: int):\n",
    "        ''' Computes the fitness subtracted by the penalty for invalid solutions (i.e. not all squares attacked or occupied).\n",
    "            The penalty function receives a parameter 'k', which indicates the current iteration number.\n",
    "        '''\n",
    "        return self.fitness_function(particle_positions) + self.penalty_function(particle_positions, k)\n",
    "\n",
    "    def optimise(self, num_iterations):\n",
    "        num_plateau_steps = 0\n",
    "\n",
    "        #features are number of fitness evaluations, fitness value, number of knights, number of covered squares.\n",
    "        #Only current best solutions are stored\n",
    "        metric_results = np.full(shape=(num_iterations, 4), fill_value=-1, dtype=np.float64)\n",
    "        stored_solutions = []\n",
    "\n",
    "        store_iteration_results(metric_results, index=0, num_fitness_evals=0, fitness_value=self.current_fitness, solution=self.current_solution)\n",
    "        stored_solutions.append(self.current_solution)\n",
    "\n",
    "        for i in range(1, num_iterations):\n",
    "            neighbour_permutation = self.rng.permutation(self.current_solution.shape[0])\n",
    "            \n",
    "            better_solution_found = False\n",
    "            for neighbour_index in neighbour_permutation:\n",
    "                neighbour_solution = self.current_solution.copy()\n",
    "                neighbour_solution[neighbour_index] = (neighbour_solution[neighbour_index]+1) % 2 \n",
    "                \n",
    "                #add another dimension so that fitness functions work the same across all algorithms\n",
    "                neighbour_fitness = self.compute_penalty_fitness(neighbour_solution[np.newaxis,:], i)[0]\n",
    "\n",
    "                #choose first neighbour with more optimal fitness (in this case, lower fitness value as we want to minimise the function)\n",
    "                # neighbour has either significantly better fitness than current solution or is within plateau tolerance\n",
    "                if (neighbour_fitness - self.current_fitness) < self.plateau_tolerance:\n",
    "                    #check if fitness is on a plateau\n",
    "                    if abs(neighbour_fitness - self.current_fitness) < self.plateau_tolerance:\n",
    "                        num_plateau_steps += 1 #increment plateau step counter\n",
    "                        \n",
    "                        #cancel optimisation if maximum number of plateau steps is reached\n",
    "                        if num_plateau_steps > self.allowed_plateau_steps:\n",
    "                            return metric_results, stored_solutions\n",
    "                        \n",
    "                    else: #reset plateau step counter if fitness is reduced\n",
    "                        num_plateau_steps = 0\n",
    "\n",
    "                    self.current_solution = neighbour_solution\n",
    "                    self.current_fitness = neighbour_fitness\n",
    "\n",
    "                    store_iteration_results(metric_results, index=i, num_fitness_evals=i, fitness_value=self.current_fitness, solution=self.current_solution)\n",
    "                    stored_solutions.append(self.current_solution)\n",
    "                    better_solution_found = True\n",
    "                    break\n",
    "            \n",
    "            # no improved solution was found among the neighbours -> peak has been reached\n",
    "            if not better_solution_found:\n",
    "                return metric_results, stored_solutions\n",
    "\n",
    "        #after final iteration\n",
    "        return metric_results, stored_solutions \n",
    "        \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def increment_indices(current_indices, max_indices):\n",
    "    current_indices[-1] += 1\n",
    "    for i in reversed(range(len(current_indices))):\n",
    "        if current_indices[i] > max_indices[i]:\n",
    "            current_indices[i] = 0\n",
    "            if i != 0:\n",
    "                current_indices[i-1] +=1\n",
    "        else:\n",
    "            break\n",
    "    return current_indices\n",
    "\n",
    "def fetch_algorithm_parameters(algorithm_config, parameter_indices):\n",
    "    config_value_list = list(algorithm_config.values())\n",
    "    parameters = [config_value_list[parameter][parameter_index] for parameter, parameter_index in enumerate(parameter_indices)]\n",
    "    \n",
    "    #flatten tuples in parameter list\n",
    "    flattened_parameters = []\n",
    "    for element in parameters:\n",
    "        if isinstance(element,tuple):\n",
    "            flattened_parameters.extend(element)\n",
    "        else:\n",
    "            flattened_parameters.append(element)\n",
    "            \n",
    "    return flattened_parameters\n",
    "\n",
    "def create_dataframe_from_results(algorithm_config, parameter_values_list, metric_results_list, \n",
    "                                  solutions_list, num_of_experiments, METRIC_FEATURE_NAMES, algorithm_name):\n",
    "    #extract function names from parameter list\n",
    "    for i in range(len(parameter_values_list)):\n",
    "        parameter_values_list[i] = [elem.__name__ if callable(elem) else elem for elem in parameter_values_list[i]]\n",
    "\n",
    "    #calculate the number of rows in metric_results_list that correspond to the same experiment\n",
    "    num_rows_per_experiment = metric_results_list.shape[0] // num_of_experiments\n",
    "\n",
    "    #extend parameter_values_list to have the same number of elements as metric_results_list\n",
    "    parameter_values_list = list(itertools.chain.from_iterable(itertools.repeat(x, num_rows_per_experiment) for x in parameter_values_list))\n",
    "\n",
    "    #extract column header names from algorithm config dict\n",
    "    param_column_headers = list(algorithm_config.keys())\n",
    "    param_column_headers = [str.split(key,\"_and_\") for key in param_column_headers] #split compound keys\n",
    "    param_column_headers = list(itertools.chain.from_iterable(param_column_headers))#flatten list\n",
    "\n",
    "    #convert numpy solution arrays to strings\n",
    "    solutions_list = [np.array2string(x.flatten(), max_line_width=np.inf) for x in solutions_list]\n",
    "\n",
    "    #create dataframes for metric values, parameter values, solutions and for the metadata valid for all conducted experiments\n",
    "    df_metric_values = pd.DataFrame(metric_results_list, columns= METRIC_FEATURE_NAMES)\n",
    "    df_param_values = pd.DataFrame(parameter_values_list, columns = param_column_headers)\n",
    "\n",
    "    #concatenate columns of dataframes\n",
    "    df_results = pd.concat([df_param_values,df_metric_values], axis=1)\n",
    "    df_results = df_results.loc[(df_metric_values!=-1).any(axis=1)] #remove unused rows\n",
    "    df_results = df_results.assign(solutions=solutions_list) #append solutions\n",
    "\n",
    "    df_results[\"algorithm\"] = algorithm_name #append information on which search algorithm was used\n",
    "    return df_results\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimentation config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run configuration for particle swarm optimisation\n",
    "pso_config = {\n",
    "    \"binary_space\": [True, False],\n",
    "    \"fitness_function_and_penalty_function\": [(fitness_space_pso_paper,None),(fitness_space_pso_paper, penalty_function),\n",
    "                                              (fitness_simple, penalty_function)],\n",
    "    \"num_particles\": [100],\n",
    "    \"c1_and_c2_and_inertia\": [(1,1,0.90), (1,1,(0.9,0.1))], #tuple of inertia values indicates that inertia is adjusted dynamically\n",
    "    \"max_velocity_and_min_velocity\": [(4,-4)],\n",
    "}\n",
    "\n",
    "#run configuration for random search\n",
    "rs_config = {\n",
    "    \"fitness_function_and_penalty_function\": [(fitness_space_pso_paper,None),(fitness_space_pso_paper, penalty_function),\n",
    "                                              (fitness_simple, penalty_function)],\n",
    "}\n",
    "\n",
    "#run configuration for stochastic hillclimb\n",
    "shc_config = {\n",
    "    \"fitness_function_and_penalty_function\": [(fitness_space_pso_paper,None),(fitness_space_pso_paper, penalty_function),\n",
    "                                              (fitness_simple, penalty_function)],\n",
    "    \"allowed_plateau_steps\": [200],\n",
    "    \"plateau_tolerance\": [0.1],\n",
    "}\n",
    "\n",
    "#meta run config for all experiments\n",
    "run_config = {\n",
    "    \"optimisation_algorithm\": [PSO, StochasticHillclimb, RandomSearch],\n",
    "    \"algorithm_configs\":[pso_config, shc_config, rs_config],\n",
    "    \"board_sizes\": [5,6,7,8,9,10,12],\n",
    "    \"runs_per_experiment\": 10,\n",
    "    \"function_evals_per_run\": 100_000,\n",
    "    \"rng_seed\": 111\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cc60526900748409e5dbfbc17568ec9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optimisation Algorithms:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a18f0fa49d240ea950df991e918fe4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Experiments:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d56400bbd46c4ced97f970884192d0a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Runs:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96e94dbcefe0433d9aa06182d1631620",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Runs:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ae50888d17a429e84bcb52281767fe9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Runs:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ef4909b37ac4fe6b8d554952eb0e04f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Runs:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d73ca135437d4a32b8176ff25f8b7c93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Runs:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e59e678879148c79baef570da2e83b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Runs:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d832ba2476e44b54a20b866db1ee5c44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Runs:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "447cb5dca26a49bcaaf972628eb2806a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Runs:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba78c34748434bcda4d7635207f27c9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Runs:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a5369b1da19411aa4672591d618701e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Runs:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f7dc278fa4c4547bb68eb538bb1cb6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Runs:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6db49efc21044ea92c166a24cb90ed8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Runs:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5084986b496a4d7891d7a03c46eb6f4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Runs:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09e4c6c3321d4359b8f82279a3695136",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Runs:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bcde7fcde6041bcb15857529aadc330",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Runs:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3a3599a92704ab79bd36336ac72146b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Runs:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f879fcca5e044a6bcc847dcf2829c15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Runs:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "333a90bbe37e4fd89b35bb2689b58e30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Runs:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b834c5966b04ed2ae5cb54135b38a1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Runs:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a45045cf0eb0484e9c9a6552f87dfded",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Runs:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b91c59dd57ad431b92414ed84dd25ecd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Runs:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "634bb752f6004e23922b51b19442ba1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Runs:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d288beb33ab4968b7edf4a6db36fe43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Runs:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff404974d24b442ca9f82a80f05890a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Runs:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rng = np.random.default_rng(run_config[\"rng_seed\"])\n",
    "NUM_METRIC_FEATURES = 4\n",
    "METRIC_FEATURE_NAMES = [\"fitness_evals\",\"fitness_values\",\"num_knights\",\"num_covered_squares\"]\n",
    "dataframe_list = []\n",
    "# run each optimisation algorithm\n",
    "for optimiser_id, algorithm in tqdm(enumerate(run_config[\"optimisation_algorithm\"]), \n",
    "    desc=\"Optimisation Algorithms\", total=len(run_config[\"optimisation_algorithm\"]), position=0, leave=False):\n",
    "\n",
    "    algorithm_config = run_config[\"algorithm_configs\"][optimiser_id] #fetch experiment config for the current optimisation algorithm\n",
    "    \n",
    "    #add board_sizes from run_config as first element of current config\n",
    "    extended_config = {\"board_sizes\":run_config[\"board_sizes\"]} \n",
    "    extended_config.update(algorithm_config)\n",
    "    algorithm_config = extended_config\n",
    "\n",
    "    max_parameter_indices = np.array([len(x)-1 for x in algorithm_config.values()], dtype=int) #compute the maximum indices for each config parameter\n",
    "    num_of_experiments = np.cumprod(max_parameter_indices + 1)[-1] #compute the number of experiments to run based on number of values in config\n",
    "    current_parameter_indices = np.zeros(len(algorithm_config), dtype= int) #initialise current parameter indices to 0\n",
    "\n",
    "    #initialise result storage. When using PSO, the list will not be completely filled \n",
    "    #because less than function_evals_per_run solutions will be provided per run. These will be removed when storing the results to the dataframe\n",
    "    metric_results_list = np.full(shape=(run_config[\"runs_per_experiment\"]*num_of_experiments*run_config[\"function_evals_per_run\"],\n",
    "                                   NUM_METRIC_FEATURES), fill_value=-1, dtype=np.float64)\n",
    "    stored_solutions_list = []\n",
    "    parameter_values_list = []\n",
    "    \n",
    "    #run all experiments\n",
    "    for experiment_index in tqdm(range(num_of_experiments), desc=\"Experiments\", position=1, leave=False):\n",
    "        parameters = fetch_algorithm_parameters(algorithm_config, current_parameter_indices)\n",
    "        parameter_values_list.append(parameters.copy())\n",
    "        parameters.append(rng) #append random number generator to parameters\n",
    "        #run all runs of the same experiment\n",
    "        for run in tqdm(range(run_config[\"runs_per_experiment\"]), desc=\"Runs\", position=2, leave=False):\n",
    "            optimiser = algorithm(*parameters) #initialise optimisation algorithm with parameters\n",
    "            metric_results, stored_solutions  = optimiser.optimise(run_config[\"function_evals_per_run\"]) #perform optimisation\n",
    "\n",
    "            start_index = experiment_index*run_config[\"runs_per_experiment\"]*run_config[\"function_evals_per_run\"] \\\n",
    "                          +run*run_config[\"function_evals_per_run\"]\n",
    "            metric_results_list[start_index:start_index+metric_results.shape[0],:] = metric_results\n",
    "            stored_solutions_list.extend(stored_solutions)\n",
    "\n",
    "        #increment indices of the current algorithm's parameters\n",
    "        current_parameter_indices = increment_indices(current_parameter_indices, max_parameter_indices)\n",
    "    \n",
    "    df = create_dataframe_from_results(algorithm_config, parameter_values_list, metric_results_list, stored_solutions_list, num_of_experiments,\n",
    "                                       METRIC_FEATURE_NAMES, algorithm_name= algorithm.__name__)\n",
    "    dataframe_list.append(df)\n",
    "\n",
    "# save dataframes to csv files\n",
    "for i, dataframe in enumerate(dataframe_list):\n",
    "    dataframe.to_csv(run_config[\"optimisation_algorithm\"][i].__name__+\"_results.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store experiment results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result Visualisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load results file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[True, True, True, [1, 2, 5], [1, 2, 5], [1, 2, 5], 'blubb', 'blubb', 'blubb']\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "lst = [True, [1,2, 5], \"blubb\"]\n",
    "blubb = list(itertools.chain.from_iterable(itertools.repeat(x, 3) for x in lst))\n",
    "print(blubb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>board_sizes</th>\n",
       "      <th>fitness_function</th>\n",
       "      <th>penalty_function</th>\n",
       "      <th>fitness_evals</th>\n",
       "      <th>fitness_values</th>\n",
       "      <th>num_knights</th>\n",
       "      <th>num_covered_squares</th>\n",
       "      <th>solutions</th>\n",
       "      <th>algorithm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29999</th>\n",
       "      <td>29999</td>\n",
       "      <td>5</td>\n",
       "      <td>fitness_simple</td>\n",
       "      <td>penalty_function</td>\n",
       "      <td>999.0</td>\n",
       "      <td>10.12</td>\n",
       "      <td>10.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>[1 0 1 0 0 1 0 1 0 1 0 0 0 0 0 0 1 1 0 0 0 0 1...</td>\n",
       "      <td>RandomSearch</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  board_sizes fitness_function  penalty_function  \\\n",
       "29999       29999            5   fitness_simple  penalty_function   \n",
       "\n",
       "       fitness_evals  fitness_values  num_knights  num_covered_squares  \\\n",
       "29999          999.0           10.12         10.0                 22.0   \n",
       "\n",
       "                                               solutions     algorithm  \n",
       "29999  [1 0 1 0 0 1 0 1 0 1 0 0 0 0 0 0 1 1 0 0 0 0 1...  RandomSearch  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n",
      "[1 0 1 0 0 1 0 1 0 1 0 0 0 0 0 0 1 1 0 0 0 0 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"RandomSearch_results.csv\")\n",
    "display(df[df[\"board_sizes\"] == 5].tail(1))\n",
    "elem = df[df[\"board_sizes\"] == 5].tail(1)[\"solutions\"].item()\n",
    "elem = elem[1:-1]\n",
    "elem = str.replace(elem, \"\\n\",\"\")\n",
    "elem = np.fromstring(elem, sep=\" \", dtype=np.uint)\n",
    "\n",
    "print(compute_num_of_covered_squares(elem))\n",
    "\n",
    "print(elem)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
